// Code generated by sparkle. DO NOT EDIT.

package exchange

import (
	"bytes"
	"encoding/json"
	"fmt"
	"math/big"
	"reflect"
	"time"

	eth "github.com/streamingfast/eth-go"
	"github.com/streamingfast/sparkle/entity"
	pbcodec "github.com/streamingfast/sparkle/pb/dfuse/ethereum/codec/v1"
	"github.com/streamingfast/sparkle/subgraph"
)

const (
	FactoryAddress = "0xc0aee478e3658e2610c5f7a4a2e1777ce9e4f2ac"
	ZeroAddress    = "0x0000000000000000000000000000000000000000"
)

var (
	FactoryAddressBytes = eth.MustNewAddress(FactoryAddress).Bytes()
	ZeroAddressBytes    = eth.MustNewAddress(ZeroAddress).Bytes()
)

// Aliases for numerical functions
var (
	S  = entity.S
	B  = entity.B
	F  = entity.NewFloat
	FL = entity.NewFloatFromLiteral
	I  = entity.NewInt
	IL = entity.NewIntFromLiteral
	bf = func() *big.Float { return new(big.Float) }
	bi = func() *big.Int { return new(big.Int) }
)

var Definition = &subgraph.Definition{
	PackageName:         "exchange",
	HighestParallelStep: 3,
	StartBlock:          10794229,
	IncludeFilter:       "",
	Entities: entity.NewRegistry(
		&User{},
		&Bundle{},
		&Factory{},
		&HourData{},
		&DayData{},
		&Token{},
		&TokenHourData{},
		&TokenDayData{},
		&Pair{},
		&PairHourData{},
		&PairDayData{},
		&LiquidityPosition{},
		&LiquidityPositionSnapshot{},
		&Transaction{},
		&Mint{},
		&Burn{},
		&Swap{},
		&DynamicDataSourceXXX{},
	),
	DDL: ddl,
	Manifest: `specVersion: 0.0.3
description: Exchange
repository: https://github.com/sushiswap/sushiswap-subgraph
schema:
  file: ./exchange.graphql
dataSources:
  - kind: ethereum/contract
    name: Factory
    network: mainnet
    source:
      address: '0xc0aee478e3658e2610c5f7a4a2e1777ce9e4f2ac'
      abi: Factory
      startBlock: 10794229
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.4
      language: wasm/assemblyscript
      file: ./src/exchange/mappings/factory.ts
      entities:
        - Factory
      abis:
        - name: Factory
          file: ../abis/UniswapV2Factory.json
        - name: Pair
          file: ../abis/UniswapV2Pair.json
        - name: SushiToken
          file: ../abis/SushiToken.json
        - name: ERC20
          file: ../abis/ERC20.json
        - name: ERC20SymbolBytes
          file: ../abis/ERC20SymbolBytes.json
        - name: ERC20NameBytes
          file: ../abis/ERC20NameBytes.json
      eventHandlers:
        - event: PairCreated(indexed address,indexed address,address,uint256)
          handler: onPairCreated
templates:
  - kind: ethereum/contract
    name: Pair
    network: mainnet
    source:
      abi: Pair
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.4
      language: wasm/assemblyscript
      file: ./src/exchange/mappings/pair.ts
      entities:
        - Bundle
        - Burn
        - LiquidityPosition
        - LiquidityPositionSnapshot
        - Mint
        - Pair
        - Swap
        - Sync
        - Token
        - Transaction
        - User
      abis:
        - name: Pair
          file: ../abis/UniswapV2Pair.json
        - name: Factory
          file: ../abis/UniswapV2Factory.json
      eventHandlers:
        - event: Mint(indexed address,uint256,uint256)
          handler: onMint
        - event: Burn(indexed address,uint256,uint256,indexed address)
          handler: onBurn
        - event: Swap(indexed address,uint256,uint256,uint256,uint256,indexed address)
          handler: onSwap
        - event: Transfer(indexed address,indexed address,uint256)
          handler: onTransfer
        - event: Sync(uint112,uint112)
          handler: onSync
`,
	GraphQLSchema: `# # Search
# type _Schema_
#   # Token
#   @fulltext(
#     name: "tokenSearch"
#     language: en
#     algorithm: rank
#     include: [{ entity: "Token", fields: [{ name: "id" }, { name: "name" }, { name: "symbol" }] }]
#   )
#   # Pair
#   @fulltext(
#     name: "pairSearch"
#     language: en
#     algorithm: rank
#     include: [{ entity: "Pair", fields: [{ name: "id" }, { name: "name" }] }]
#   )
#   # User
#   @fulltext(name: "userSearch", language: en, algorithm: rank, include: [{ entity: "User", fields: [{ name: "id" }] }])

# User
type User @entity {
  # Address
  id: ID!

  # Liquidity Positions
  liquidityPositions: [LiquidityPosition!]! @derivedFrom(field: "user")
}

# Bundle
type Bundle @entity {
  id: ID!

  # price of ETH usd
  ethPrice: BigDecimal! @parallel(step: 3)
}

# Factory
type Factory @entity {
  # Contract address
  id: ID!

  # Pair count
  pairCount: BigInt! @parallel(step: 1, type: SUM)

  # Volume USD
  volumeUSD: BigDecimal! @parallel(step: 3, type: SUM)

  # Volume ETH
  volumeETH: BigDecimal! @parallel(step: 3, type: SUM)

  # Untracked volume
  untrackedVolumeUSD: BigDecimal! @parallel(step: 3, type: SUM)

  # Liquidity USD
  liquidityUSD: BigDecimal! @parallel(step: 3)

  # Liquidity ETH
  liquidityETH: BigDecimal! @parallel(step: 3)

  # Transaction count
  txCount: BigInt! @parallel(step: 3, type: SUM)

  # Token count
  tokenCount: BigInt! @parallel(step: 3, type: SUM)

  # User count
  userCount: BigInt! @parallel(step: 3, type: SUM)

  # Pairs
  pairs: [Pair!]! @derivedFrom(field: "factory")

  # Tokens
  tokens: [Token!]! @derivedFrom(field: "factory")

  # Hour data
  hourData: [HourData!]! @derivedFrom(field: "factory")

  # Day data
  dayData: [DayData!]! @derivedFrom(field: "factory")
}

# Hour Data
type HourData @entity {
  # start of hour timestamp
  id: ID!

  # date
  date: Int! @parallel(step: 3)

  # factory
  factory: Factory!

  # volume
  volumeETH: BigDecimal! @parallel(step: 3, type: SUM)
  volumeUSD: BigDecimal! @parallel(step: 3, type: SUM)
  untrackedVolume: BigDecimal! @parallel(step: 3, type: SUM)

  # liquidity
  liquidityETH: BigDecimal! @parallel(step: 3)
  liquidityUSD: BigDecimal! @parallel(step: 3)

  # tx count
  txCount: BigInt! @parallel(step: 3, type: SUM)
}

# Day Data
type DayData @entity {
  # timestamp / 86400
  id: ID!

  # date
  date: Int! @parallel(step: 3)

  # factory
  factory: Factory!

  # volume
  volumeETH: BigDecimal! @parallel(step: 3, type: SUM)
  volumeUSD: BigDecimal! @parallel(step: 3, type: SUM)
  untrackedVolume: BigDecimal! @parallel(step: 3, type: SUM)

  # liquidity
  liquidityETH: BigDecimal! @parallel(step: 3)
  liquidityUSD: BigDecimal! @parallel(step: 3)

  # tx count
  txCount: BigInt! @parallel(step: 3, type: SUM)
}

# Token
type Token @entity {
  # token address
  id: ID!

  # factory
  factory: Factory!

  # mirrored from the smart contract
  symbol: String! @parallel(step: 1)
  name: String! @parallel(step: 1)
  decimals: BigInt! @parallel(step: 1)

  # used for other stats like marketcap
  totalSupply: BigInt!  @parallel(step: 3, type: SUM)

  # token specific volume
  volume: BigDecimal!  @parallel(step: 3, type: SUM)
  volumeUSD: BigDecimal! @parallel(step: 3, type: SUM) @sql(index: false)
  untrackedVolumeUSD: BigDecimal!  @parallel(step: 3, type: SUM)

  # transactions across all pairs
  txCount: BigInt!  @parallel(step: 3, type: SUM)

  # liquidity across all pairs
  liquidity: BigDecimal!  @parallel(step: 3, type: SUM)

  derivedETH: BigDecimal! @parallel(step: 2)

  whitelistPairs: [Pair!]! @parallel(step: 3)

  # Token hour data
  hourData: [TokenHourData!]! @derivedFrom(field: "token")

  # Token day data
  dayData: [TokenDayData!]! @derivedFrom(field: "token")

  # Base pairs
  basePairs: [Pair!]! @derivedFrom(field: "token0")

  # Quote pairs
  quotePairs: [Pair!]! @derivedFrom(field: "token1")

  # Base pairs day data
  basePairsDayData: [PairDayData!]! @derivedFrom(field: "token0")

  # Quote pairs day data
  quotePairsDayData: [PairDayData!]! @derivedFrom(field: "token1")
}

# Token hour data
type TokenHourData @entity {
  # token id - hour start timestamp
  id: ID!

  # date - hour start timestamp
  date: Int! @parallel(step: 3)

  # token
  token: Token! @parallel(step: 3)

  # volume
  volume: BigDecimal! @parallel(step: 3, type: SUM)
  volumeETH: BigDecimal! @parallel(step: 3, type: SUM)
  volumeUSD: BigDecimal! @parallel(step: 3, type: SUM)

  # tx count
  txCount: BigInt! @parallel(step: 3, type: SUM)

  # liquidity
  liquidity: BigDecimal! @parallel(step: 3)
  liquidityETH: BigDecimal! @parallel(step: 3)
  liquidityUSD: BigDecimal! @parallel(step: 3)

  # price usd
  priceUSD: BigDecimal! @parallel(step: 3)
}

# Token day data
type TokenDayData @entity {
  # token id - day start timestamp
  id: ID!

  # date - day start timestamp
  date: Int! @parallel(step: 3)

  # token
  token: Token! @parallel(step: 3)

  # volume
  volume: BigDecimal! @parallel(step: 3, type: SUM)
  volumeETH: BigDecimal! @parallel(step: 3, type: SUM)
  volumeUSD: BigDecimal! @parallel(step: 3, type: SUM)

  # tx count
  txCount: BigInt! @parallel(step: 3, type: SUM)

  # liquidity
  liquidity: BigDecimal! @parallel(step: 3)
  liquidityETH: BigDecimal! @parallel(step: 3)
  liquidityUSD: BigDecimal! @parallel(step: 3)

  # price usd
  priceUSD: BigDecimal! @parallel(step: 3)
}

# Pair
type Pair @entity {
  # Contract address
  id: ID!

  # Factory
  factory: Factory!

  # Name
  name: String! @parallel(step: 1)

  # mirrored from the smart contract
  token0: Token! @parallel(step: 1)
  token1: Token! @parallel(step: 1)

  reserve0: BigDecimal! @parallel(step: 2)
  reserve1: BigDecimal! @parallel(step: 2)
  totalSupply: BigDecimal! @parallel(step: 3, type: SUM)

  # derived liquidity
  reserveETH: BigDecimal! @parallel(step: 3)
  reserveUSD: BigDecimal! @parallel(step: 3) @sql(index: false)

  # used for separating per pair reserves and global
  trackedReserveETH: BigDecimal! @sql(index: false)

  # Price in terms of the asset pair
  token0Price: BigDecimal! @parallel(step: 2)
  token1Price: BigDecimal! @parallel(step: 2)

  # lifetime volume stats
  volumeToken0: BigDecimal! @parallel(step: 3, type: SUM)
  volumeToken1: BigDecimal! @parallel(step: 3, type: SUM)
  volumeUSD: BigDecimal! @parallel(step: 3, type: SUM) @sql(index: false)
  untrackedVolumeUSD: BigDecimal!  @parallel(step: 3, type: SUM)
  txCount: BigInt!  @parallel(step: 3, type: SUM)

  # Fields used to help derived relationship
  # used to detect new exchanges
  liquidityProviderCount: BigInt! @parallel(step: 3, type: SUM)

  # lca: BigDecimal!
  # lcad: BigDecimal!

  # Liquidity positions
  liquidityPositions: [LiquidityPosition!]! @derivedFrom(field: "pair")

  # Liquidity position snapshots
  liquidityPositionSnapshots: [LiquidityPositionSnapshot!]! @derivedFrom(field: "pair")

  # Pair day data
  dayData: [PairDayData!]! @derivedFrom(field: "pair")

  # Pair hour data
  hourData: [PairHourData!]! @derivedFrom(field: "pair")

  # Transactions
  mints: [Mint!]! @derivedFrom(field: "pair")
  burns: [Burn!]! @derivedFrom(field: "pair")
  swaps: [Swap!]! @derivedFrom(field: "pair")

  # Created at
  timestamp: BigInt! @parallel(step: 1)
  block: BigInt! @parallel(step: 1)
}

# Pair hour data
type PairHourData @entity {
  # pair.id - hour start timestamp
  id: ID!

  # date - hour start timestamp
  date: Int! @parallel(step: 3)

  # pair
  pair: Pair! @parallel(step: 3)

  # reserves
  reserve0: BigDecimal! @parallel(step: 3)
  reserve1: BigDecimal! @parallel(step: 3)

  # derived liquidity
  reserveUSD: BigDecimal!

  # volume
  volumeToken0: BigDecimal! @parallel(step: 3, type: SUM)
  volumeToken1: BigDecimal! @parallel(step: 3, type: SUM)

  # volume usd
  volumeUSD: BigDecimal! @parallel(step: 3, type: SUM)

  # tx count
  txCount: BigInt! @parallel(step: 3, type: SUM)
}

# Pair day data
type PairDayData @entity {
  # pair id - day start timestamp
  id: ID!

  # date - day start timestamp
  date: Int! @parallel(step: 3)

  # pair
  pair: Pair! @parallel(step: 3)

  # token0
  token0: Token! @parallel(step: 3)

  # token1
  token1: Token! @parallel(step: 3)

  # reserves
  reserve0: BigDecimal! @parallel(step: 3)
  reserve1: BigDecimal! @parallel(step: 3)

  # total supply for LP historical returns
  totalSupply: BigDecimal! @parallel(step: 3, type: SUM)

  # derived liquidity
  reserveUSD: BigDecimal! @parallel(step: 3)

  # volume
  volumeToken0: BigDecimal! @parallel(step: 3, type: SUM)
  volumeToken1: BigDecimal! @parallel(step: 3, type: SUM)

  # volume usd
  volumeUSD: BigDecimal!  @parallel(step: 3, type: SUM)

  # tx count
  txCount: BigInt! @parallel(step: 3, type: SUM)
}

# liquidity position
type LiquidityPosition @entity {
  id: ID!
  user: User! @parallel(step: 3)
  pair: Pair! @parallel(step: 3)
  liquidityTokenBalance: BigDecimal! @parallel(step: 3)
  snapshots: [LiquidityPositionSnapshot]! @derivedFrom(field: "liquidityPosition")
  block: Int! @parallel(step: 3)
  timestamp: Int! @parallel(step: 3)
}

# saved over time for return calculations, gets created and never updated
type LiquidityPositionSnapshot @entity {
  id: ID!
  liquidityPosition: LiquidityPosition! @parallel(step: 3)
  timestamp: Int! @parallel(step: 3) # saved for fast historical lookups
  block: Int! @parallel(step: 3) # saved for fast historical lookups
  user: User! @parallel(step: 3) # reference to user
  pair: Pair! @parallel(step: 3) # reference to pair
  token0PriceUSD: BigDecimal! @parallel(step: 3) # snapshot of token0 price
  token1PriceUSD: BigDecimal! @parallel(step: 3) # snapshot of token1 price
  reserve0: BigDecimal! @parallel(step: 3) # snapshot of pair token0 reserves
  reserve1: BigDecimal! @parallel(step: 3) # snapshot of pair token1 reserves
  reserveUSD: BigDecimal! @parallel(step: 3) # snapshot of pair reserves in USD
  liquidityTokenTotalSupply: BigDecimal! @parallel(step: 3, type: SUM) # snapshot of pool token supply
  # snapshot of users pool token balance
  liquidityTokenBalance: BigDecimal! @parallel(step: 3)
}

# transaction
type Transaction @entity {
  # transaction hash
  id: ID!
  blockNumber: BigInt! @parallel(step: 3)
  timestamp: BigInt! @parallel(step: 3)
  # This is not the reverse of Mint.transaction; it is only used to
  # track incomplete mints (similar for burns and swaps)
  mints: [Mint]!
  burns: [Burn]!
  swaps: [Swap]!
}

# mint
type Mint @entity {
  # transaction hash - index of mint in transaction mints array
  id: ID!
  transaction: Transaction! @parallel(step: 3)
  timestamp: BigInt! @parallel(step: 3) # need this to pull recent txns for specific token or pair
  pair: Pair! @parallel(step: 3)

  # populated from the primary Transfer event
  to: String! @parallel(step: 3)
  liquidity: BigDecimal! @parallel(step: 3)

  # populated from the Mint event
  sender: String @parallel(step: 3)
  amount0: BigDecimal @parallel(step: 3)
  amount1: BigDecimal @parallel(step: 3)
  logIndex: BigInt @parallel(step: 3)
  # derived amount based on available prices of tokens
  amountUSD: BigDecimal @parallel(step: 3)

  # optional fee fields, if a Transfer event is fired in _mintFee
  feeTo: String @parallel(step: 3)
  feeLiquidity: BigDecimal @parallel(step: 3)
}

# burn
type Burn @entity {
  # transaction hash - index of burn in transaction burns array
  id: ID!
  transaction: Transaction! @parallel(step: 3)
  timestamp: BigInt! @parallel(step: 3) # need this to pull recent txns for specific token or pair
  pair: Pair! @parallel(step: 3)

  # populated from the primary Transfer event
  liquidity: BigDecimal! @parallel(step: 3)

  # populated from the Burn event
  sender: String @parallel(step: 3)
  amount0: BigDecimal @parallel(step: 3)
  amount1: BigDecimal @parallel(step: 3)
  to: String @parallel(step: 3)
  logIndex: BigInt @parallel(step: 3)
  # derived amount based on available prices of tokens
  amountUSD: BigDecimal @parallel(step: 3)

  # mark uncomplete in ETH case
  complete: Boolean! @parallel(step: 3)

  # optional fee fields, if a Transfer event is fired in _mintFee
  feeTo: String @parallel(step: 3)
  feeLiquidity: BigDecimal @parallel(step: 3)
}

# swap
type Swap @entity {
  # transaction hash - index of swap in transaction swaps array
  id: ID!
  transaction: Transaction! @parallel(step: 3)
  timestamp: BigInt! @parallel(step: 3) # need this to pull recent txns for specific token or pair
  pair: Pair! @parallel(step: 3)

  # populated from the Swap event
  sender: String! @parallel(step: 3)
  amount0In: BigDecimal! @parallel(step: 3)
  amount1In: BigDecimal! @parallel(step: 3)
  amount0Out: BigDecimal! @parallel(step: 3)
  amount1Out: BigDecimal! @parallel(step: 3)
  to: String! @parallel(step: 3)
  logIndex: BigInt @parallel(step: 3)

  # derived info
  amountUSD: BigDecimal! @parallel(step: 3)
}
`,
	Abis: map[string]string{
		"ERC20": `[
  {
    "inputs": [
      {
        "internalType": "string",
        "name": "name_",
        "type": "string"
      },
      {
        "internalType": "string",
        "name": "symbol_",
        "type": "string"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "constructor"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "owner",
        "type": "address"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "spender",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "value",
        "type": "uint256"
      }
    ],
    "name": "Approval",
    "type": "event"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "from",
        "type": "address"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "to",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "value",
        "type": "uint256"
      }
    ],
    "name": "Transfer",
    "type": "event"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "owner",
        "type": "address"
      },
      {
        "internalType": "address",
        "name": "spender",
        "type": "address"
      }
    ],
    "name": "allowance",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "spender",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "amount",
        "type": "uint256"
      }
    ],
    "name": "approve",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "account",
        "type": "address"
      }
    ],
    "name": "balanceOf",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "decimals",
    "outputs": [
      {
        "internalType": "uint8",
        "name": "",
        "type": "uint8"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "spender",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "subtractedValue",
        "type": "uint256"
      }
    ],
    "name": "decreaseAllowance",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "spender",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "addedValue",
        "type": "uint256"
      }
    ],
    "name": "increaseAllowance",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "name",
    "outputs": [
      {
        "internalType": "string",
        "name": "",
        "type": "string"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "symbol",
    "outputs": [
      {
        "internalType": "string",
        "name": "",
        "type": "string"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "totalSupply",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "recipient",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "amount",
        "type": "uint256"
      }
    ],
    "name": "transfer",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "sender",
        "type": "address"
      },
      {
        "internalType": "address",
        "name": "recipient",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "amount",
        "type": "uint256"
      }
    ],
    "name": "transferFrom",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  }
]
`,
		"ERC20NameBytes": `[
  {
    "constant": true,
    "inputs": [],
    "name": "name",
    "outputs": [
      {
        "internalType": "bytes32",
        "name": "",
        "type": "bytes32"
      }
    ],
    "payable": false,
    "stateMutability": "view",
    "type": "function"
  }
]
`,
		"ERC20SymbolBytes": `[
  {
    "constant": true,
    "inputs": [],
    "name": "symbol",
    "outputs": [
      {
        "internalType": "bytes32",
        "name": "",
        "type": "bytes32"
      }
    ],
    "payable": false,
    "stateMutability": "view",
    "type": "function"
  }
]
`,
		"Factory": `[
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "_feeToSetter",
        "type": "address"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "constructor"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "token0",
        "type": "address"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "token1",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "address",
        "name": "pair",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "name": "PairCreated",
    "type": "event"
  },
  {
    "inputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "name": "allPairs",
    "outputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "allPairsLength",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "tokenA",
        "type": "address"
      },
      {
        "internalType": "address",
        "name": "tokenB",
        "type": "address"
      }
    ],
    "name": "createPair",
    "outputs": [
      {
        "internalType": "address",
        "name": "pair",
        "type": "address"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "feeTo",
    "outputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "feeToSetter",
    "outputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      },
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "name": "getPair",
    "outputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "migrator",
    "outputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "pairCodeHash",
    "outputs": [
      {
        "internalType": "bytes32",
        "name": "",
        "type": "bytes32"
      }
    ],
    "stateMutability": "pure",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "_feeTo",
        "type": "address"
      }
    ],
    "name": "setFeeTo",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "_feeToSetter",
        "type": "address"
      }
    ],
    "name": "setFeeToSetter",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "_migrator",
        "type": "address"
      }
    ],
    "name": "setMigrator",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  }
]
`,
		"Pair": `[
  {
    "inputs": [],
    "stateMutability": "nonpayable",
    "type": "constructor"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "owner",
        "type": "address"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "spender",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "value",
        "type": "uint256"
      }
    ],
    "name": "Approval",
    "type": "event"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "sender",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "amount0",
        "type": "uint256"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "amount1",
        "type": "uint256"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "to",
        "type": "address"
      }
    ],
    "name": "Burn",
    "type": "event"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "sender",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "amount0",
        "type": "uint256"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "amount1",
        "type": "uint256"
      }
    ],
    "name": "Mint",
    "type": "event"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "sender",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "amount0In",
        "type": "uint256"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "amount1In",
        "type": "uint256"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "amount0Out",
        "type": "uint256"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "amount1Out",
        "type": "uint256"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "to",
        "type": "address"
      }
    ],
    "name": "Swap",
    "type": "event"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": false,
        "internalType": "uint112",
        "name": "reserve0",
        "type": "uint112"
      },
      {
        "indexed": false,
        "internalType": "uint112",
        "name": "reserve1",
        "type": "uint112"
      }
    ],
    "name": "Sync",
    "type": "event"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "from",
        "type": "address"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "to",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "value",
        "type": "uint256"
      }
    ],
    "name": "Transfer",
    "type": "event"
  },
  {
    "inputs": [],
    "name": "DOMAIN_SEPARATOR",
    "outputs": [
      {
        "internalType": "bytes32",
        "name": "",
        "type": "bytes32"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "MINIMUM_LIQUIDITY",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "PERMIT_TYPEHASH",
    "outputs": [
      {
        "internalType": "bytes32",
        "name": "",
        "type": "bytes32"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      },
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "name": "allowance",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "spender",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "value",
        "type": "uint256"
      }
    ],
    "name": "approve",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "name": "balanceOf",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "to",
        "type": "address"
      }
    ],
    "name": "burn",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "amount0",
        "type": "uint256"
      },
      {
        "internalType": "uint256",
        "name": "amount1",
        "type": "uint256"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "decimals",
    "outputs": [
      {
        "internalType": "uint8",
        "name": "",
        "type": "uint8"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "factory",
    "outputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "getReserves",
    "outputs": [
      {
        "internalType": "uint112",
        "name": "_reserve0",
        "type": "uint112"
      },
      {
        "internalType": "uint112",
        "name": "_reserve1",
        "type": "uint112"
      },
      {
        "internalType": "uint32",
        "name": "_blockTimestampLast",
        "type": "uint32"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "_token0",
        "type": "address"
      },
      {
        "internalType": "address",
        "name": "_token1",
        "type": "address"
      }
    ],
    "name": "initialize",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "kLast",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "to",
        "type": "address"
      }
    ],
    "name": "mint",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "liquidity",
        "type": "uint256"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "name",
    "outputs": [
      {
        "internalType": "string",
        "name": "",
        "type": "string"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "name": "nonces",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "owner",
        "type": "address"
      },
      {
        "internalType": "address",
        "name": "spender",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "value",
        "type": "uint256"
      },
      {
        "internalType": "uint256",
        "name": "deadline",
        "type": "uint256"
      },
      {
        "internalType": "uint8",
        "name": "v",
        "type": "uint8"
      },
      {
        "internalType": "bytes32",
        "name": "r",
        "type": "bytes32"
      },
      {
        "internalType": "bytes32",
        "name": "s",
        "type": "bytes32"
      }
    ],
    "name": "permit",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "price0CumulativeLast",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "price1CumulativeLast",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "to",
        "type": "address"
      }
    ],
    "name": "skim",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "uint256",
        "name": "amount0Out",
        "type": "uint256"
      },
      {
        "internalType": "uint256",
        "name": "amount1Out",
        "type": "uint256"
      },
      {
        "internalType": "address",
        "name": "to",
        "type": "address"
      },
      {
        "internalType": "bytes",
        "name": "data",
        "type": "bytes"
      }
    ],
    "name": "swap",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "symbol",
    "outputs": [
      {
        "internalType": "string",
        "name": "",
        "type": "string"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "sync",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "token0",
    "outputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "token1",
    "outputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "totalSupply",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "to",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "value",
        "type": "uint256"
      }
    ],
    "name": "transfer",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "from",
        "type": "address"
      },
      {
        "internalType": "address",
        "name": "to",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "value",
        "type": "uint256"
      }
    ],
    "name": "transferFrom",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  }
]
`,
		"SushiToken": `[
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "owner",
        "type": "address"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "spender",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "value",
        "type": "uint256"
      }
    ],
    "name": "Approval",
    "type": "event"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "delegator",
        "type": "address"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "fromDelegate",
        "type": "address"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "toDelegate",
        "type": "address"
      }
    ],
    "name": "DelegateChanged",
    "type": "event"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "delegate",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "previousBalance",
        "type": "uint256"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "newBalance",
        "type": "uint256"
      }
    ],
    "name": "DelegateVotesChanged",
    "type": "event"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "previousOwner",
        "type": "address"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "newOwner",
        "type": "address"
      }
    ],
    "name": "OwnershipTransferred",
    "type": "event"
  },
  {
    "anonymous": false,
    "inputs": [
      {
        "indexed": true,
        "internalType": "address",
        "name": "from",
        "type": "address"
      },
      {
        "indexed": true,
        "internalType": "address",
        "name": "to",
        "type": "address"
      },
      {
        "indexed": false,
        "internalType": "uint256",
        "name": "value",
        "type": "uint256"
      }
    ],
    "name": "Transfer",
    "type": "event"
  },
  {
    "inputs": [],
    "name": "DELEGATION_TYPEHASH",
    "outputs": [
      {
        "internalType": "bytes32",
        "name": "",
        "type": "bytes32"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "DOMAIN_TYPEHASH",
    "outputs": [
      {
        "internalType": "bytes32",
        "name": "",
        "type": "bytes32"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "owner",
        "type": "address"
      },
      {
        "internalType": "address",
        "name": "spender",
        "type": "address"
      }
    ],
    "name": "allowance",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "spender",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "amount",
        "type": "uint256"
      }
    ],
    "name": "approve",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "account",
        "type": "address"
      }
    ],
    "name": "balanceOf",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      },
      {
        "internalType": "uint32",
        "name": "",
        "type": "uint32"
      }
    ],
    "name": "checkpoints",
    "outputs": [
      {
        "internalType": "uint32",
        "name": "fromBlock",
        "type": "uint32"
      },
      {
        "internalType": "uint256",
        "name": "votes",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "decimals",
    "outputs": [
      {
        "internalType": "uint8",
        "name": "",
        "type": "uint8"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "spender",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "subtractedValue",
        "type": "uint256"
      }
    ],
    "name": "decreaseAllowance",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "delegatee",
        "type": "address"
      }
    ],
    "name": "delegate",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "delegatee",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "nonce",
        "type": "uint256"
      },
      {
        "internalType": "uint256",
        "name": "expiry",
        "type": "uint256"
      },
      {
        "internalType": "uint8",
        "name": "v",
        "type": "uint8"
      },
      {
        "internalType": "bytes32",
        "name": "r",
        "type": "bytes32"
      },
      {
        "internalType": "bytes32",
        "name": "s",
        "type": "bytes32"
      }
    ],
    "name": "delegateBySig",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "delegator",
        "type": "address"
      }
    ],
    "name": "delegates",
    "outputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "account",
        "type": "address"
      }
    ],
    "name": "getCurrentVotes",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "account",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "blockNumber",
        "type": "uint256"
      }
    ],
    "name": "getPriorVotes",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "spender",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "addedValue",
        "type": "uint256"
      }
    ],
    "name": "increaseAllowance",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "_to",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "_amount",
        "type": "uint256"
      }
    ],
    "name": "mint",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "name",
    "outputs": [
      {
        "internalType": "string",
        "name": "",
        "type": "string"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "name": "nonces",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "name": "numCheckpoints",
    "outputs": [
      {
        "internalType": "uint32",
        "name": "",
        "type": "uint32"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "owner",
    "outputs": [
      {
        "internalType": "address",
        "name": "",
        "type": "address"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "renounceOwnership",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "symbol",
    "outputs": [
      {
        "internalType": "string",
        "name": "",
        "type": "string"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [],
    "name": "totalSupply",
    "outputs": [
      {
        "internalType": "uint256",
        "name": "",
        "type": "uint256"
      }
    ],
    "stateMutability": "view",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "recipient",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "amount",
        "type": "uint256"
      }
    ],
    "name": "transfer",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "sender",
        "type": "address"
      },
      {
        "internalType": "address",
        "name": "recipient",
        "type": "address"
      },
      {
        "internalType": "uint256",
        "name": "amount",
        "type": "uint256"
      }
    ],
    "name": "transferFrom",
    "outputs": [
      {
        "internalType": "bool",
        "name": "",
        "type": "bool"
      }
    ],
    "stateMutability": "nonpayable",
    "type": "function"
  },
  {
    "inputs": [
      {
        "internalType": "address",
        "name": "newOwner",
        "type": "address"
      }
    ],
    "name": "transferOwnership",
    "outputs": [],
    "stateMutability": "nonpayable",
    "type": "function"
  }
]
`,
	},
	New: func(base subgraph.Base) subgraph.Subgraph {
		return &Subgraph{
			Base:               base,
			DynamicDataSources: map[string]*DynamicDataSourceXXX{},
		}
	},
	MergeFunc: func(step int, cached, new entity.Interface) entity.Interface {
		switch new.(type) {
		case interface {
			Merge(step int, new *User)
		}:
			var c *User
			if cached == nil {
				return new.(*User)
			}
			c = cached.(*User)
			el := new.(*User)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *Bundle)
		}:
			var c *Bundle
			if cached == nil {
				return new.(*Bundle)
			}
			c = cached.(*Bundle)
			el := new.(*Bundle)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *Factory)
		}:
			var c *Factory
			if cached == nil {
				return new.(*Factory)
			}
			c = cached.(*Factory)
			el := new.(*Factory)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *HourData)
		}:
			var c *HourData
			if cached == nil {
				return new.(*HourData)
			}
			c = cached.(*HourData)
			el := new.(*HourData)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *DayData)
		}:
			var c *DayData
			if cached == nil {
				return new.(*DayData)
			}
			c = cached.(*DayData)
			el := new.(*DayData)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *Token)
		}:
			var c *Token
			if cached == nil {
				return new.(*Token)
			}
			c = cached.(*Token)
			el := new.(*Token)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *TokenHourData)
		}:
			var c *TokenHourData
			if cached == nil {
				return new.(*TokenHourData)
			}
			c = cached.(*TokenHourData)
			el := new.(*TokenHourData)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *TokenDayData)
		}:
			var c *TokenDayData
			if cached == nil {
				return new.(*TokenDayData)
			}
			c = cached.(*TokenDayData)
			el := new.(*TokenDayData)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *Pair)
		}:
			var c *Pair
			if cached == nil {
				return new.(*Pair)
			}
			c = cached.(*Pair)
			el := new.(*Pair)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *PairHourData)
		}:
			var c *PairHourData
			if cached == nil {
				return new.(*PairHourData)
			}
			c = cached.(*PairHourData)
			el := new.(*PairHourData)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *PairDayData)
		}:
			var c *PairDayData
			if cached == nil {
				return new.(*PairDayData)
			}
			c = cached.(*PairDayData)
			el := new.(*PairDayData)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *LiquidityPosition)
		}:
			var c *LiquidityPosition
			if cached == nil {
				return new.(*LiquidityPosition)
			}
			c = cached.(*LiquidityPosition)
			el := new.(*LiquidityPosition)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *LiquidityPositionSnapshot)
		}:
			var c *LiquidityPositionSnapshot
			if cached == nil {
				return new.(*LiquidityPositionSnapshot)
			}
			c = cached.(*LiquidityPositionSnapshot)
			el := new.(*LiquidityPositionSnapshot)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *Transaction)
		}:
			var c *Transaction
			if cached == nil {
				return new.(*Transaction)
			}
			c = cached.(*Transaction)
			el := new.(*Transaction)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *Mint)
		}:
			var c *Mint
			if cached == nil {
				return new.(*Mint)
			}
			c = cached.(*Mint)
			el := new.(*Mint)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *Burn)
		}:
			var c *Burn
			if cached == nil {
				return new.(*Burn)
			}
			c = cached.(*Burn)
			el := new.(*Burn)
			el.Merge(step, c)
			return el
		case interface {
			Merge(step int, new *Swap)
		}:
			var c *Swap
			if cached == nil {
				return new.(*Swap)
			}
			c = cached.(*Swap)
			el := new.(*Swap)
			el.Merge(step, c)
			return el
		case *DynamicDataSourceXXX:
			return new
		}
		panic("unsupported merge type")
	},
}

type Subgraph struct {
	subgraph.Base

	CurrentBlockDynamicDataSources map[string]*DynamicDataSourceXXX
	DynamicDataSources             map[string]*DynamicDataSourceXXX
}

// User
type User struct {
	entity.Base
}

func NewUser(id string) *User {
	return &User{
		Base: entity.NewBase(id),
	}
}

func (_ *User) SkipDBLookup() bool {
	return false
}
func (next *User) Merge(step int, cached *User) {
}

// Bundle
type Bundle struct {
	entity.Base
	EthPrice entity.Float `db:"eth_price" csv:"eth_price"`
}

func NewBundle(id string) *Bundle {
	return &Bundle{
		Base:     entity.NewBase(id),
		EthPrice: FL(0),
	}
}

func (_ *Bundle) SkipDBLookup() bool {
	return false
}
func (next *Bundle) Merge(step int, cached *Bundle) {
	if step == 4 {
		if next.MutatedOnStep != 3 {
			next.EthPrice = cached.EthPrice
		}
	}
}

// Factory
type Factory struct {
	entity.Base
	PairCount          entity.Int   `db:"pair_count" csv:"pair_count"`
	VolumeUSD          entity.Float `db:"volume_usd" csv:"volume_usd"`
	VolumeETH          entity.Float `db:"volume_eth" csv:"volume_eth"`
	UntrackedVolumeUSD entity.Float `db:"untracked_volume_usd" csv:"untracked_volume_usd"`
	LiquidityUSD       entity.Float `db:"liquidity_usd" csv:"liquidity_usd"`
	LiquidityETH       entity.Float `db:"liquidity_eth" csv:"liquidity_eth"`
	TxCount            entity.Int   `db:"tx_count" csv:"tx_count"`
	TokenCount         entity.Int   `db:"token_count" csv:"token_count"`
	UserCount          entity.Int   `db:"user_count" csv:"user_count"`
}

func NewFactory(id string) *Factory {
	return &Factory{
		Base:               entity.NewBase(id),
		PairCount:          IL(0),
		VolumeUSD:          FL(0),
		VolumeETH:          FL(0),
		UntrackedVolumeUSD: FL(0),
		LiquidityUSD:       FL(0),
		LiquidityETH:       FL(0),
		TxCount:            IL(0),
		TokenCount:         IL(0),
		UserCount:          IL(0),
	}
}

func (_ *Factory) SkipDBLookup() bool {
	return false
}
func (next *Factory) Merge(step int, cached *Factory) {
	if step == 2 {
		next.PairCount = entity.IntAdd(next.PairCount, cached.PairCount)
		if next.MutatedOnStep != 1 {
		}
	}
	if step == 4 {
		next.VolumeUSD = entity.FloatAdd(next.VolumeUSD, cached.VolumeUSD)
		next.VolumeETH = entity.FloatAdd(next.VolumeETH, cached.VolumeETH)
		next.UntrackedVolumeUSD = entity.FloatAdd(next.UntrackedVolumeUSD, cached.UntrackedVolumeUSD)
		next.TxCount = entity.IntAdd(next.TxCount, cached.TxCount)
		next.TokenCount = entity.IntAdd(next.TokenCount, cached.TokenCount)
		next.UserCount = entity.IntAdd(next.UserCount, cached.UserCount)
		if next.MutatedOnStep != 3 {
			next.LiquidityUSD = cached.LiquidityUSD
			next.LiquidityETH = cached.LiquidityETH
		}
	}
}

// HourData
type HourData struct {
	entity.Base
	Date            int64        `db:"date" csv:"date"`
	Factory         string       `db:"factory" csv:"factory"`
	VolumeETH       entity.Float `db:"volume_eth" csv:"volume_eth"`
	VolumeUSD       entity.Float `db:"volume_usd" csv:"volume_usd"`
	UntrackedVolume entity.Float `db:"untracked_volume" csv:"untracked_volume"`
	LiquidityETH    entity.Float `db:"liquidity_eth" csv:"liquidity_eth"`
	LiquidityUSD    entity.Float `db:"liquidity_usd" csv:"liquidity_usd"`
	TxCount         entity.Int   `db:"tx_count" csv:"tx_count"`
}

func NewHourData(id string) *HourData {
	return &HourData{
		Base:            entity.NewBase(id),
		VolumeETH:       FL(0),
		VolumeUSD:       FL(0),
		UntrackedVolume: FL(0),
		LiquidityETH:    FL(0),
		LiquidityUSD:    FL(0),
		TxCount:         IL(0),
	}
}

func (_ *HourData) SkipDBLookup() bool {
	return false
}
func (next *HourData) Merge(step int, cached *HourData) {
	if step == 4 {
		next.VolumeETH = entity.FloatAdd(next.VolumeETH, cached.VolumeETH)
		next.VolumeUSD = entity.FloatAdd(next.VolumeUSD, cached.VolumeUSD)
		next.UntrackedVolume = entity.FloatAdd(next.UntrackedVolume, cached.UntrackedVolume)
		next.TxCount = entity.IntAdd(next.TxCount, cached.TxCount)
		if next.MutatedOnStep != 3 {
			next.Date = cached.Date
			next.LiquidityETH = cached.LiquidityETH
			next.LiquidityUSD = cached.LiquidityUSD
		}
	}
}

// DayData
type DayData struct {
	entity.Base
	Date            int64        `db:"date" csv:"date"`
	Factory         string       `db:"factory" csv:"factory"`
	VolumeETH       entity.Float `db:"volume_eth" csv:"volume_eth"`
	VolumeUSD       entity.Float `db:"volume_usd" csv:"volume_usd"`
	UntrackedVolume entity.Float `db:"untracked_volume" csv:"untracked_volume"`
	LiquidityETH    entity.Float `db:"liquidity_eth" csv:"liquidity_eth"`
	LiquidityUSD    entity.Float `db:"liquidity_usd" csv:"liquidity_usd"`
	TxCount         entity.Int   `db:"tx_count" csv:"tx_count"`
}

func NewDayData(id string) *DayData {
	return &DayData{
		Base:            entity.NewBase(id),
		VolumeETH:       FL(0),
		VolumeUSD:       FL(0),
		UntrackedVolume: FL(0),
		LiquidityETH:    FL(0),
		LiquidityUSD:    FL(0),
		TxCount:         IL(0),
	}
}

func (_ *DayData) SkipDBLookup() bool {
	return false
}
func (next *DayData) Merge(step int, cached *DayData) {
	if step == 4 {
		next.VolumeETH = entity.FloatAdd(next.VolumeETH, cached.VolumeETH)
		next.VolumeUSD = entity.FloatAdd(next.VolumeUSD, cached.VolumeUSD)
		next.UntrackedVolume = entity.FloatAdd(next.UntrackedVolume, cached.UntrackedVolume)
		next.TxCount = entity.IntAdd(next.TxCount, cached.TxCount)
		if next.MutatedOnStep != 3 {
			next.Date = cached.Date
			next.LiquidityETH = cached.LiquidityETH
			next.LiquidityUSD = cached.LiquidityUSD
		}
	}
}

// Token
type Token struct {
	entity.Base
	Factory            string                  `db:"factory" csv:"factory"`
	Symbol             string                  `db:"symbol" csv:"symbol"`
	Name               string                  `db:"name" csv:"name"`
	Decimals           entity.Int              `db:"decimals" csv:"decimals"`
	TotalSupply        entity.Int              `db:"total_supply" csv:"total_supply"`
	Volume             entity.Float            `db:"volume" csv:"volume"`
	VolumeUSD          entity.Float            `db:"volume_usd" csv:"volume_usd"`
	UntrackedVolumeUSD entity.Float            `db:"untracked_volume_usd" csv:"untracked_volume_usd"`
	TxCount            entity.Int              `db:"tx_count" csv:"tx_count"`
	Liquidity          entity.Float            `db:"liquidity" csv:"liquidity"`
	DerivedETH         entity.Float            `db:"derived_eth" csv:"derived_eth"`
	WhitelistPairs     entity.LocalStringArray `db:"whitelist_pairs" csv:"whitelist_pairs"`
}

func NewToken(id string) *Token {
	return &Token{
		Base:               entity.NewBase(id),
		Decimals:           IL(0),
		TotalSupply:        IL(0),
		Volume:             FL(0),
		VolumeUSD:          FL(0),
		UntrackedVolumeUSD: FL(0),
		TxCount:            IL(0),
		Liquidity:          FL(0),
		DerivedETH:         FL(0),
	}
}

func (_ *Token) SkipDBLookup() bool {
	return false
}
func (next *Token) Merge(step int, cached *Token) {
	if step == 2 {
		if next.MutatedOnStep != 1 {
			next.Symbol = cached.Symbol
			next.Name = cached.Name
			next.Decimals = cached.Decimals
		}
	}
	if step == 3 {
		if next.MutatedOnStep != 2 {
			next.DerivedETH = cached.DerivedETH
		}
	}
	if step == 4 {
		next.TotalSupply = entity.IntAdd(next.TotalSupply, cached.TotalSupply)
		next.Volume = entity.FloatAdd(next.Volume, cached.Volume)
		next.VolumeUSD = entity.FloatAdd(next.VolumeUSD, cached.VolumeUSD)
		next.UntrackedVolumeUSD = entity.FloatAdd(next.UntrackedVolumeUSD, cached.UntrackedVolumeUSD)
		next.TxCount = entity.IntAdd(next.TxCount, cached.TxCount)
		next.Liquidity = entity.FloatAdd(next.Liquidity, cached.Liquidity)
		if next.MutatedOnStep != 3 {
			next.WhitelistPairs = cached.WhitelistPairs
		}
	}
}

// TokenHourData
type TokenHourData struct {
	entity.Base
	Date         int64        `db:"date" csv:"date"`
	Token        string       `db:"token" csv:"token"`
	Volume       entity.Float `db:"volume" csv:"volume"`
	VolumeETH    entity.Float `db:"volume_eth" csv:"volume_eth"`
	VolumeUSD    entity.Float `db:"volume_usd" csv:"volume_usd"`
	TxCount      entity.Int   `db:"tx_count" csv:"tx_count"`
	Liquidity    entity.Float `db:"liquidity" csv:"liquidity"`
	LiquidityETH entity.Float `db:"liquidity_eth" csv:"liquidity_eth"`
	LiquidityUSD entity.Float `db:"liquidity_usd" csv:"liquidity_usd"`
	PriceUSD     entity.Float `db:"price_usd" csv:"price_usd"`
}

func NewTokenHourData(id string) *TokenHourData {
	return &TokenHourData{
		Base:         entity.NewBase(id),
		Volume:       FL(0),
		VolumeETH:    FL(0),
		VolumeUSD:    FL(0),
		TxCount:      IL(0),
		Liquidity:    FL(0),
		LiquidityETH: FL(0),
		LiquidityUSD: FL(0),
		PriceUSD:     FL(0),
	}
}

func (_ *TokenHourData) SkipDBLookup() bool {
	return false
}
func (next *TokenHourData) Merge(step int, cached *TokenHourData) {
	if step == 4 {
		next.Volume = entity.FloatAdd(next.Volume, cached.Volume)
		next.VolumeETH = entity.FloatAdd(next.VolumeETH, cached.VolumeETH)
		next.VolumeUSD = entity.FloatAdd(next.VolumeUSD, cached.VolumeUSD)
		next.TxCount = entity.IntAdd(next.TxCount, cached.TxCount)
		if next.MutatedOnStep != 3 {
			next.Date = cached.Date
			next.Token = cached.Token
			next.Liquidity = cached.Liquidity
			next.LiquidityETH = cached.LiquidityETH
			next.LiquidityUSD = cached.LiquidityUSD
			next.PriceUSD = cached.PriceUSD
		}
	}
}

// TokenDayData
type TokenDayData struct {
	entity.Base
	Date         int64        `db:"date" csv:"date"`
	Token        string       `db:"token" csv:"token"`
	Volume       entity.Float `db:"volume" csv:"volume"`
	VolumeETH    entity.Float `db:"volume_eth" csv:"volume_eth"`
	VolumeUSD    entity.Float `db:"volume_usd" csv:"volume_usd"`
	TxCount      entity.Int   `db:"tx_count" csv:"tx_count"`
	Liquidity    entity.Float `db:"liquidity" csv:"liquidity"`
	LiquidityETH entity.Float `db:"liquidity_eth" csv:"liquidity_eth"`
	LiquidityUSD entity.Float `db:"liquidity_usd" csv:"liquidity_usd"`
	PriceUSD     entity.Float `db:"price_usd" csv:"price_usd"`
}

func NewTokenDayData(id string) *TokenDayData {
	return &TokenDayData{
		Base:         entity.NewBase(id),
		Volume:       FL(0),
		VolumeETH:    FL(0),
		VolumeUSD:    FL(0),
		TxCount:      IL(0),
		Liquidity:    FL(0),
		LiquidityETH: FL(0),
		LiquidityUSD: FL(0),
		PriceUSD:     FL(0),
	}
}

func (_ *TokenDayData) SkipDBLookup() bool {
	return false
}
func (next *TokenDayData) Merge(step int, cached *TokenDayData) {
	if step == 4 {
		next.Volume = entity.FloatAdd(next.Volume, cached.Volume)
		next.VolumeETH = entity.FloatAdd(next.VolumeETH, cached.VolumeETH)
		next.VolumeUSD = entity.FloatAdd(next.VolumeUSD, cached.VolumeUSD)
		next.TxCount = entity.IntAdd(next.TxCount, cached.TxCount)
		if next.MutatedOnStep != 3 {
			next.Date = cached.Date
			next.Token = cached.Token
			next.Liquidity = cached.Liquidity
			next.LiquidityETH = cached.LiquidityETH
			next.LiquidityUSD = cached.LiquidityUSD
			next.PriceUSD = cached.PriceUSD
		}
	}
}

// Pair
type Pair struct {
	entity.Base
	Factory                string       `db:"factory" csv:"factory"`
	Name                   string       `db:"name" csv:"name"`
	Token0                 string       `db:"token_0" csv:"token_0"`
	Token1                 string       `db:"token_1" csv:"token_1"`
	Reserve0               entity.Float `db:"reserve_0" csv:"reserve_0"`
	Reserve1               entity.Float `db:"reserve_1" csv:"reserve_1"`
	TotalSupply            entity.Float `db:"total_supply" csv:"total_supply"`
	ReserveETH             entity.Float `db:"reserve_eth" csv:"reserve_eth"`
	ReserveUSD             entity.Float `db:"reserve_usd" csv:"reserve_usd"`
	TrackedReserveETH      entity.Float `db:"tracked_reserve_eth" csv:"tracked_reserve_eth"`
	Token0Price            entity.Float `db:"token_0_price" csv:"token_0_price"`
	Token1Price            entity.Float `db:"token_1_price" csv:"token_1_price"`
	VolumeToken0           entity.Float `db:"volume_token_0" csv:"volume_token_0"`
	VolumeToken1           entity.Float `db:"volume_token_1" csv:"volume_token_1"`
	VolumeUSD              entity.Float `db:"volume_usd" csv:"volume_usd"`
	UntrackedVolumeUSD     entity.Float `db:"untracked_volume_usd" csv:"untracked_volume_usd"`
	TxCount                entity.Int   `db:"tx_count" csv:"tx_count"`
	LiquidityProviderCount entity.Int   `db:"liquidity_provider_count" csv:"liquidity_provider_count"`
	Timestamp              entity.Int   `db:"timestamp" csv:"timestamp"`
	Block                  entity.Int   `db:"block" csv:"block"`
}

func NewPair(id string) *Pair {
	return &Pair{
		Base:                   entity.NewBase(id),
		Reserve0:               FL(0),
		Reserve1:               FL(0),
		TotalSupply:            FL(0),
		ReserveETH:             FL(0),
		ReserveUSD:             FL(0),
		TrackedReserveETH:      FL(0),
		Token0Price:            FL(0),
		Token1Price:            FL(0),
		VolumeToken0:           FL(0),
		VolumeToken1:           FL(0),
		VolumeUSD:              FL(0),
		UntrackedVolumeUSD:     FL(0),
		TxCount:                IL(0),
		LiquidityProviderCount: IL(0),
		Timestamp:              IL(0),
		Block:                  IL(0),
	}
}

func (_ *Pair) SkipDBLookup() bool {
	return false
}
func (next *Pair) Merge(step int, cached *Pair) {
	if step == 2 {
		if next.MutatedOnStep != 1 {
			next.Name = cached.Name
			next.Token0 = cached.Token0
			next.Token1 = cached.Token1
			next.Timestamp = cached.Timestamp
			next.Block = cached.Block
		}
	}
	if step == 3 {
		if next.MutatedOnStep != 2 {
			next.Reserve0 = cached.Reserve0
			next.Reserve1 = cached.Reserve1
			next.Token0Price = cached.Token0Price
			next.Token1Price = cached.Token1Price
		}
	}
	if step == 4 {
		next.TotalSupply = entity.FloatAdd(next.TotalSupply, cached.TotalSupply)
		next.VolumeToken0 = entity.FloatAdd(next.VolumeToken0, cached.VolumeToken0)
		next.VolumeToken1 = entity.FloatAdd(next.VolumeToken1, cached.VolumeToken1)
		next.VolumeUSD = entity.FloatAdd(next.VolumeUSD, cached.VolumeUSD)
		next.UntrackedVolumeUSD = entity.FloatAdd(next.UntrackedVolumeUSD, cached.UntrackedVolumeUSD)
		next.TxCount = entity.IntAdd(next.TxCount, cached.TxCount)
		next.LiquidityProviderCount = entity.IntAdd(next.LiquidityProviderCount, cached.LiquidityProviderCount)
		if next.MutatedOnStep != 3 {
			next.ReserveETH = cached.ReserveETH
			next.ReserveUSD = cached.ReserveUSD
		}
	}
}

// PairHourData
type PairHourData struct {
	entity.Base
	Date         int64        `db:"date" csv:"date"`
	Pair         string       `db:"pair" csv:"pair"`
	Reserve0     entity.Float `db:"reserve_0" csv:"reserve_0"`
	Reserve1     entity.Float `db:"reserve_1" csv:"reserve_1"`
	ReserveUSD   entity.Float `db:"reserve_usd" csv:"reserve_usd"`
	VolumeToken0 entity.Float `db:"volume_token_0" csv:"volume_token_0"`
	VolumeToken1 entity.Float `db:"volume_token_1" csv:"volume_token_1"`
	VolumeUSD    entity.Float `db:"volume_usd" csv:"volume_usd"`
	TxCount      entity.Int   `db:"tx_count" csv:"tx_count"`
}

func NewPairHourData(id string) *PairHourData {
	return &PairHourData{
		Base:         entity.NewBase(id),
		Reserve0:     FL(0),
		Reserve1:     FL(0),
		ReserveUSD:   FL(0),
		VolumeToken0: FL(0),
		VolumeToken1: FL(0),
		VolumeUSD:    FL(0),
		TxCount:      IL(0),
	}
}

func (_ *PairHourData) SkipDBLookup() bool {
	return false
}
func (next *PairHourData) Merge(step int, cached *PairHourData) {
	if step == 4 {
		next.VolumeToken0 = entity.FloatAdd(next.VolumeToken0, cached.VolumeToken0)
		next.VolumeToken1 = entity.FloatAdd(next.VolumeToken1, cached.VolumeToken1)
		next.VolumeUSD = entity.FloatAdd(next.VolumeUSD, cached.VolumeUSD)
		next.TxCount = entity.IntAdd(next.TxCount, cached.TxCount)
		if next.MutatedOnStep != 3 {
			next.Date = cached.Date
			next.Pair = cached.Pair
			next.Reserve0 = cached.Reserve0
			next.Reserve1 = cached.Reserve1
		}
	}
}

// PairDayData
type PairDayData struct {
	entity.Base
	Date         int64        `db:"date" csv:"date"`
	Pair         string       `db:"pair" csv:"pair"`
	Token0       string       `db:"token_0" csv:"token_0"`
	Token1       string       `db:"token_1" csv:"token_1"`
	Reserve0     entity.Float `db:"reserve_0" csv:"reserve_0"`
	Reserve1     entity.Float `db:"reserve_1" csv:"reserve_1"`
	TotalSupply  entity.Float `db:"total_supply" csv:"total_supply"`
	ReserveUSD   entity.Float `db:"reserve_usd" csv:"reserve_usd"`
	VolumeToken0 entity.Float `db:"volume_token_0" csv:"volume_token_0"`
	VolumeToken1 entity.Float `db:"volume_token_1" csv:"volume_token_1"`
	VolumeUSD    entity.Float `db:"volume_usd" csv:"volume_usd"`
	TxCount      entity.Int   `db:"tx_count" csv:"tx_count"`
}

func NewPairDayData(id string) *PairDayData {
	return &PairDayData{
		Base:         entity.NewBase(id),
		Reserve0:     FL(0),
		Reserve1:     FL(0),
		TotalSupply:  FL(0),
		ReserveUSD:   FL(0),
		VolumeToken0: FL(0),
		VolumeToken1: FL(0),
		VolumeUSD:    FL(0),
		TxCount:      IL(0),
	}
}

func (_ *PairDayData) SkipDBLookup() bool {
	return false
}
func (next *PairDayData) Merge(step int, cached *PairDayData) {
	if step == 4 {
		next.TotalSupply = entity.FloatAdd(next.TotalSupply, cached.TotalSupply)
		next.VolumeToken0 = entity.FloatAdd(next.VolumeToken0, cached.VolumeToken0)
		next.VolumeToken1 = entity.FloatAdd(next.VolumeToken1, cached.VolumeToken1)
		next.VolumeUSD = entity.FloatAdd(next.VolumeUSD, cached.VolumeUSD)
		next.TxCount = entity.IntAdd(next.TxCount, cached.TxCount)
		if next.MutatedOnStep != 3 {
			next.Date = cached.Date
			next.Pair = cached.Pair
			next.Token0 = cached.Token0
			next.Token1 = cached.Token1
			next.Reserve0 = cached.Reserve0
			next.Reserve1 = cached.Reserve1
			next.ReserveUSD = cached.ReserveUSD
		}
	}
}

// LiquidityPosition
type LiquidityPosition struct {
	entity.Base
	User                  string       `db:"user" csv:"user"`
	Pair                  string       `db:"pair" csv:"pair"`
	LiquidityTokenBalance entity.Float `db:"liquidity_token_balance" csv:"liquidity_token_balance"`
	Block                 int64        `db:"block" csv:"block"`
	Timestamp             int64        `db:"timestamp" csv:"timestamp"`
}

func NewLiquidityPosition(id string) *LiquidityPosition {
	return &LiquidityPosition{
		Base:                  entity.NewBase(id),
		LiquidityTokenBalance: FL(0),
	}
}

func (_ *LiquidityPosition) SkipDBLookup() bool {
	return false
}
func (next *LiquidityPosition) Merge(step int, cached *LiquidityPosition) {
	if step == 4 {
		if next.MutatedOnStep != 3 {
			next.User = cached.User
			next.Pair = cached.Pair
			next.LiquidityTokenBalance = cached.LiquidityTokenBalance
			next.Block = cached.Block
			next.Timestamp = cached.Timestamp
		}
	}
}

// LiquidityPositionSnapshot
type LiquidityPositionSnapshot struct {
	entity.Base
	LiquidityPosition         string       `db:"liquidity_position" csv:"liquidity_position"`
	Timestamp                 int64        `db:"timestamp" csv:"timestamp"`
	Block                     int64        `db:"block" csv:"block"`
	User                      string       `db:"user" csv:"user"`
	Pair                      string       `db:"pair" csv:"pair"`
	Token0PriceUSD            entity.Float `db:"token_0_price_usd" csv:"token_0_price_usd"`
	Token1PriceUSD            entity.Float `db:"token_1_price_usd" csv:"token_1_price_usd"`
	Reserve0                  entity.Float `db:"reserve_0" csv:"reserve_0"`
	Reserve1                  entity.Float `db:"reserve_1" csv:"reserve_1"`
	ReserveUSD                entity.Float `db:"reserve_usd" csv:"reserve_usd"`
	LiquidityTokenTotalSupply entity.Float `db:"liquidity_token_total_supply" csv:"liquidity_token_total_supply"`
	LiquidityTokenBalance     entity.Float `db:"liquidity_token_balance" csv:"liquidity_token_balance"`
}

func NewLiquidityPositionSnapshot(id string) *LiquidityPositionSnapshot {
	return &LiquidityPositionSnapshot{
		Base:                      entity.NewBase(id),
		Token0PriceUSD:            FL(0),
		Token1PriceUSD:            FL(0),
		Reserve0:                  FL(0),
		Reserve1:                  FL(0),
		ReserveUSD:                FL(0),
		LiquidityTokenTotalSupply: FL(0),
		LiquidityTokenBalance:     FL(0),
	}
}

func (_ *LiquidityPositionSnapshot) SkipDBLookup() bool {
	return false
}
func (next *LiquidityPositionSnapshot) Merge(step int, cached *LiquidityPositionSnapshot) {
	if step == 4 {
		next.LiquidityTokenTotalSupply = entity.FloatAdd(next.LiquidityTokenTotalSupply, cached.LiquidityTokenTotalSupply)
		if next.MutatedOnStep != 3 {
			next.LiquidityPosition = cached.LiquidityPosition
			next.Timestamp = cached.Timestamp
			next.Block = cached.Block
			next.User = cached.User
			next.Pair = cached.Pair
			next.Token0PriceUSD = cached.Token0PriceUSD
			next.Token1PriceUSD = cached.Token1PriceUSD
			next.Reserve0 = cached.Reserve0
			next.Reserve1 = cached.Reserve1
			next.ReserveUSD = cached.ReserveUSD
			next.LiquidityTokenBalance = cached.LiquidityTokenBalance
		}
	}
}

// Transaction
type Transaction struct {
	entity.Base
	BlockNumber entity.Int              `db:"block_number" csv:"block_number"`
	Timestamp   entity.Int              `db:"timestamp" csv:"timestamp"`
	Mints       entity.LocalStringArray `db:"mints,nullable" csv:"mints"`
	Burns       entity.LocalStringArray `db:"burns,nullable" csv:"burns"`
	Swaps       entity.LocalStringArray `db:"swaps,nullable" csv:"swaps"`
}

func NewTransaction(id string) *Transaction {
	return &Transaction{
		Base:        entity.NewBase(id),
		BlockNumber: IL(0),
		Timestamp:   IL(0),
	}
}

func (_ *Transaction) SkipDBLookup() bool {
	return false
}
func (next *Transaction) Merge(step int, cached *Transaction) {
	if step == 4 {
		if next.MutatedOnStep != 3 {
			next.BlockNumber = cached.BlockNumber
			next.Timestamp = cached.Timestamp
		}
	}
}

// Mint
type Mint struct {
	entity.Base
	Transaction  string        `db:"transaction" csv:"transaction"`
	Timestamp    entity.Int    `db:"timestamp" csv:"timestamp"`
	Pair         string        `db:"pair" csv:"pair"`
	To           string        `db:"to" csv:"to"`
	Liquidity    entity.Float  `db:"liquidity" csv:"liquidity"`
	Sender       *string       `db:"sender,nullable" csv:"sender"`
	Amount0      *entity.Float `db:"amount_0,nullable" csv:"amount_0"`
	Amount1      *entity.Float `db:"amount_1,nullable" csv:"amount_1"`
	LogIndex     *entity.Int   `db:"log_index,nullable" csv:"log_index"`
	AmountUSD    *entity.Float `db:"amount_usd,nullable" csv:"amount_usd"`
	FeeTo        *string       `db:"fee_to,nullable" csv:"fee_to"`
	FeeLiquidity *entity.Float `db:"fee_liquidity,nullable" csv:"fee_liquidity"`
}

func NewMint(id string) *Mint {
	return &Mint{
		Base:      entity.NewBase(id),
		Timestamp: IL(0),
		Liquidity: FL(0),
	}
}

func (_ *Mint) SkipDBLookup() bool {
	return false
}
func (next *Mint) Merge(step int, cached *Mint) {
	if step == 4 {
		if next.MutatedOnStep != 3 {
			next.Transaction = cached.Transaction
			next.Timestamp = cached.Timestamp
			next.Pair = cached.Pair
			next.To = cached.To
			next.Liquidity = cached.Liquidity
			next.Sender = cached.Sender
			next.Amount0 = cached.Amount0
			next.Amount1 = cached.Amount1
			next.LogIndex = cached.LogIndex
			next.AmountUSD = cached.AmountUSD
			next.FeeTo = cached.FeeTo
			next.FeeLiquidity = cached.FeeLiquidity
		}
	}
}

// Burn
type Burn struct {
	entity.Base
	Transaction  string        `db:"transaction" csv:"transaction"`
	Timestamp    entity.Int    `db:"timestamp" csv:"timestamp"`
	Pair         string        `db:"pair" csv:"pair"`
	Liquidity    entity.Float  `db:"liquidity" csv:"liquidity"`
	Sender       *string       `db:"sender,nullable" csv:"sender"`
	Amount0      *entity.Float `db:"amount_0,nullable" csv:"amount_0"`
	Amount1      *entity.Float `db:"amount_1,nullable" csv:"amount_1"`
	To           *string       `db:"to,nullable" csv:"to"`
	LogIndex     *entity.Int   `db:"log_index,nullable" csv:"log_index"`
	AmountUSD    *entity.Float `db:"amount_usd,nullable" csv:"amount_usd"`
	Complete     entity.Bool   `db:"complete" csv:"complete"`
	FeeTo        *string       `db:"fee_to,nullable" csv:"fee_to"`
	FeeLiquidity *entity.Float `db:"fee_liquidity,nullable" csv:"fee_liquidity"`
}

func NewBurn(id string) *Burn {
	return &Burn{
		Base:      entity.NewBase(id),
		Timestamp: IL(0),
		Liquidity: FL(0),
	}
}

func (_ *Burn) SkipDBLookup() bool {
	return false
}
func (next *Burn) Merge(step int, cached *Burn) {
	if step == 4 {
		if next.MutatedOnStep != 3 {
			next.Transaction = cached.Transaction
			next.Timestamp = cached.Timestamp
			next.Pair = cached.Pair
			next.Liquidity = cached.Liquidity
			next.Sender = cached.Sender
			next.Amount0 = cached.Amount0
			next.Amount1 = cached.Amount1
			next.To = cached.To
			next.LogIndex = cached.LogIndex
			next.AmountUSD = cached.AmountUSD
			next.Complete = cached.Complete
			next.FeeTo = cached.FeeTo
			next.FeeLiquidity = cached.FeeLiquidity
		}
	}
}

// Swap
type Swap struct {
	entity.Base
	Transaction string       `db:"transaction" csv:"transaction"`
	Timestamp   entity.Int   `db:"timestamp" csv:"timestamp"`
	Pair        string       `db:"pair" csv:"pair"`
	Sender      string       `db:"sender" csv:"sender"`
	Amount0In   entity.Float `db:"amount_0_in" csv:"amount_0_in"`
	Amount1In   entity.Float `db:"amount_1_in" csv:"amount_1_in"`
	Amount0Out  entity.Float `db:"amount_0_out" csv:"amount_0_out"`
	Amount1Out  entity.Float `db:"amount_1_out" csv:"amount_1_out"`
	To          string       `db:"to" csv:"to"`
	LogIndex    *entity.Int  `db:"log_index,nullable" csv:"log_index"`
	AmountUSD   entity.Float `db:"amount_usd" csv:"amount_usd"`
}

func NewSwap(id string) *Swap {
	return &Swap{
		Base:       entity.NewBase(id),
		Timestamp:  IL(0),
		Amount0In:  FL(0),
		Amount1In:  FL(0),
		Amount0Out: FL(0),
		Amount1Out: FL(0),
		AmountUSD:  FL(0),
	}
}

func (_ *Swap) SkipDBLookup() bool {
	return false
}
func (next *Swap) Merge(step int, cached *Swap) {
	if step == 4 {
		if next.MutatedOnStep != 3 {
			next.Transaction = cached.Transaction
			next.Timestamp = cached.Timestamp
			next.Pair = cached.Pair
			next.Sender = cached.Sender
			next.Amount0In = cached.Amount0In
			next.Amount1In = cached.Amount1In
			next.Amount0Out = cached.Amount0Out
			next.Amount1Out = cached.Amount1Out
			next.To = cached.To
			next.LogIndex = cached.LogIndex
			next.AmountUSD = cached.AmountUSD
		}
	}
}

func (s *Subgraph) HandleBlock(block *pbcodec.Block) error {
	idx := uint32(0)
	s.CurrentBlockDynamicDataSources = make(map[string]*DynamicDataSourceXXX)

	for _, trace := range block.TransactionTraces {
		logs := trace.Logs()
		for _, log := range logs {
			var ethLog interface{} = log
			eventLog := codecLogToEthLog(ethLog.(*pbcodec.Log), idx)
			idx++
			if bytes.Equal(FactoryAddressBytes, log.Address) || s.IsDynamicDataSource(eth.Address(log.Address).Pretty()) {
				ev, err := DecodeEvent(eventLog, block, trace)
				if err != nil {
					return fmt.Errorf("parsing event: %w", err)
				}
				if err := s.HandleEvent(ev); err != nil {
					return fmt.Errorf("handling event: %w", err)
				}

			}
		}
	}

	if len(s.CurrentBlockDynamicDataSources) == 0 {
		return nil
	}

	for _, trace := range block.TransactionTraces {
		logs := trace.Logs()
		for _, log := range logs {
			var ethLog interface{} = log
			eventLog := codecLogToEthLog(ethLog.(*pbcodec.Log), idx)
			idx++
			if s.IsCurrentDynamicDataSource(eth.Address(log.Address).Pretty()) {
				ev, err := DecodeEvent(eventLog, block, trace)
				if err != nil {
					return fmt.Errorf("parsing event: %w", err)
				}
				if err := s.HandleEvent(ev); err != nil {
					return fmt.Errorf("handling event: %w", err)
				}

			}
		}
	}

	for k, v := range s.CurrentBlockDynamicDataSources {
		s.DynamicDataSources[k] = v
	}

	return nil
}
func (s *Subgraph) HandleEvent(ev interface{}) error {
	switch e := ev.(type) {

	case *FactoryPairCreatedEvent:
		if err := s.HandleFactoryPairCreatedEvent(e); err != nil {
			return fmt.Errorf("handling FactoryPairCreated event: %w", err)
		}

	case *PairBurnEvent:
		if err := s.HandlePairBurnEvent(e); err != nil {
			return fmt.Errorf("handling PairBurn event: %w", err)
		}
	case *PairMintEvent:
		if err := s.HandlePairMintEvent(e); err != nil {
			return fmt.Errorf("handling PairMint event: %w", err)
		}
	case *PairSwapEvent:
		if err := s.HandlePairSwapEvent(e); err != nil {
			return fmt.Errorf("handling PairSwap event: %w", err)
		}
	case *PairSyncEvent:
		if err := s.HandlePairSyncEvent(e); err != nil {
			return fmt.Errorf("handling PairSync event: %w", err)
		}
	case *PairTransferEvent:
		if err := s.HandlePairTransferEvent(e); err != nil {
			return fmt.Errorf("handling PairTransfer event: %w", err)
		}
	}

	return nil
}

func codecLogToEthLog(l *pbcodec.Log, idx uint32) *eth.Log {
	return &eth.Log{
		Address:    l.Address,
		Topics:     l.Topics,
		Data:       l.Data,
		Index:      l.Index,
		BlockIndex: idx,
	}
}

// Factory
// FactoryPairCreated event

type FactoryPairCreatedEvent struct {
	*entity.BaseEvent
	LogAddress eth.Address
	LogIndex   int

	// Fields
	Token0 eth.Address `eth:",indexed"`
	Token1 eth.Address `eth:",indexed"`
	Pair   eth.Address `eth:""`
}

var hashFactoryPairCreatedEvent = eth.Keccak256([]byte("PairCreated(address,address,address,uint256)"))

func IsFactoryPairCreatedEvent(log *eth.Log) bool {
	return bytes.Equal(log.Topics[0], hashFactoryPairCreatedEvent)
}

func NewFactoryPairCreatedEvent(log *eth.Log, block *pbcodec.Block, trace *pbcodec.TransactionTrace) (*FactoryPairCreatedEvent, error) {
	var err error
	ev := &FactoryPairCreatedEvent{
		BaseEvent:  &entity.BaseEvent{},
		LogAddress: log.Address,
		LogIndex:   int(log.BlockIndex),
	}

	ev.SetBlockAndTransaction(block, trace)

	dec := eth.NewLogDecoder(log)
	if _, err := dec.ReadTopic(); err != nil {
		return nil, fmt.Errorf("reading topic 0: %w", err)
	}
	f0, err := dec.ReadTypedTopic("address")
	if err != nil {
		return nil, fmt.Errorf("reading token0: %w", err)
	}
	ev.Token0 = f0.(eth.Address)
	f1, err := dec.ReadTypedTopic("address")
	if err != nil {
		return nil, fmt.Errorf("reading token1: %w", err)
	}
	ev.Token1 = f1.(eth.Address)
	ev.Pair, err = dec.DataDecoder.ReadAddress()
	if err != nil {
		return nil, fmt.Errorf("reading pair:  %w", err)
	}
	return ev, nil
}

// Pair
// PairApproval event

type PairApprovalEvent struct {
	*entity.BaseEvent
	LogAddress eth.Address
	LogIndex   int

	// Fields
	Owner   eth.Address `eth:",indexed"`
	Spender eth.Address `eth:",indexed"`
	Value   *big.Int    `eth:""`
}

var hashPairApprovalEvent = eth.Keccak256([]byte("Approval(address,address,uint256)"))

func IsPairApprovalEvent(log *eth.Log) bool {
	return bytes.Equal(log.Topics[0], hashPairApprovalEvent)
}

func NewPairApprovalEvent(log *eth.Log, block *pbcodec.Block, trace *pbcodec.TransactionTrace) (*PairApprovalEvent, error) {
	var err error
	ev := &PairApprovalEvent{
		BaseEvent:  &entity.BaseEvent{},
		LogAddress: log.Address,
		LogIndex:   int(log.BlockIndex),
	}

	ev.SetBlockAndTransaction(block, trace)

	dec := eth.NewLogDecoder(log)
	if _, err := dec.ReadTopic(); err != nil {
		return nil, fmt.Errorf("reading topic 0: %w", err)
	}
	f0, err := dec.ReadTypedTopic("address")
	if err != nil {
		return nil, fmt.Errorf("reading owner: %w", err)
	}
	ev.Owner = f0.(eth.Address)
	f1, err := dec.ReadTypedTopic("address")
	if err != nil {
		return nil, fmt.Errorf("reading spender: %w", err)
	}
	ev.Spender = f1.(eth.Address)
	ev.Value, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading value:  %w", err)
	}
	return ev, nil
}

// PairBurn event

type PairBurnEvent struct {
	*entity.BaseEvent
	LogAddress eth.Address
	LogIndex   int

	// Fields
	Sender  eth.Address `eth:",indexed"`
	Amount0 *big.Int    `eth:""`
	Amount1 *big.Int    `eth:""`
	To      eth.Address `eth:",indexed"`
}

var hashPairBurnEvent = eth.Keccak256([]byte("Burn(address,uint256,uint256,address)"))

func IsPairBurnEvent(log *eth.Log) bool {
	return bytes.Equal(log.Topics[0], hashPairBurnEvent)
}

func NewPairBurnEvent(log *eth.Log, block *pbcodec.Block, trace *pbcodec.TransactionTrace) (*PairBurnEvent, error) {
	var err error
	ev := &PairBurnEvent{
		BaseEvent:  &entity.BaseEvent{},
		LogAddress: log.Address,
		LogIndex:   int(log.BlockIndex),
	}

	ev.SetBlockAndTransaction(block, trace)

	dec := eth.NewLogDecoder(log)
	if _, err := dec.ReadTopic(); err != nil {
		return nil, fmt.Errorf("reading topic 0: %w", err)
	}
	f0, err := dec.ReadTypedTopic("address")
	if err != nil {
		return nil, fmt.Errorf("reading sender: %w", err)
	}
	ev.Sender = f0.(eth.Address)
	ev.Amount0, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading amount0:  %w", err)
	}
	ev.Amount1, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading amount1:  %w", err)
	}
	f3, err := dec.ReadTypedTopic("address")
	if err != nil {
		return nil, fmt.Errorf("reading to: %w", err)
	}
	ev.To = f3.(eth.Address)
	return ev, nil
}

// PairMint event

type PairMintEvent struct {
	*entity.BaseEvent
	LogAddress eth.Address
	LogIndex   int

	// Fields
	Sender  eth.Address `eth:",indexed"`
	Amount0 *big.Int    `eth:""`
	Amount1 *big.Int    `eth:""`
}

var hashPairMintEvent = eth.Keccak256([]byte("Mint(address,uint256,uint256)"))

func IsPairMintEvent(log *eth.Log) bool {
	return bytes.Equal(log.Topics[0], hashPairMintEvent)
}

func NewPairMintEvent(log *eth.Log, block *pbcodec.Block, trace *pbcodec.TransactionTrace) (*PairMintEvent, error) {
	var err error
	ev := &PairMintEvent{
		BaseEvent:  &entity.BaseEvent{},
		LogAddress: log.Address,
		LogIndex:   int(log.BlockIndex),
	}

	ev.SetBlockAndTransaction(block, trace)

	dec := eth.NewLogDecoder(log)
	if _, err := dec.ReadTopic(); err != nil {
		return nil, fmt.Errorf("reading topic 0: %w", err)
	}
	f0, err := dec.ReadTypedTopic("address")
	if err != nil {
		return nil, fmt.Errorf("reading sender: %w", err)
	}
	ev.Sender = f0.(eth.Address)
	ev.Amount0, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading amount0:  %w", err)
	}
	ev.Amount1, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading amount1:  %w", err)
	}
	return ev, nil
}

// PairSwap event

type PairSwapEvent struct {
	*entity.BaseEvent
	LogAddress eth.Address
	LogIndex   int

	// Fields
	Sender     eth.Address `eth:",indexed"`
	Amount0In  *big.Int    `eth:""`
	Amount1In  *big.Int    `eth:""`
	Amount0Out *big.Int    `eth:""`
	Amount1Out *big.Int    `eth:""`
	To         eth.Address `eth:",indexed"`
}

var hashPairSwapEvent = eth.Keccak256([]byte("Swap(address,uint256,uint256,uint256,uint256,address)"))

func IsPairSwapEvent(log *eth.Log) bool {
	return bytes.Equal(log.Topics[0], hashPairSwapEvent)
}

func NewPairSwapEvent(log *eth.Log, block *pbcodec.Block, trace *pbcodec.TransactionTrace) (*PairSwapEvent, error) {
	var err error
	ev := &PairSwapEvent{
		BaseEvent:  &entity.BaseEvent{},
		LogAddress: log.Address,
		LogIndex:   int(log.BlockIndex),
	}

	ev.SetBlockAndTransaction(block, trace)

	dec := eth.NewLogDecoder(log)
	if _, err := dec.ReadTopic(); err != nil {
		return nil, fmt.Errorf("reading topic 0: %w", err)
	}
	f0, err := dec.ReadTypedTopic("address")
	if err != nil {
		return nil, fmt.Errorf("reading sender: %w", err)
	}
	ev.Sender = f0.(eth.Address)
	ev.Amount0In, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading amount0In:  %w", err)
	}
	ev.Amount1In, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading amount1In:  %w", err)
	}
	ev.Amount0Out, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading amount0Out:  %w", err)
	}
	ev.Amount1Out, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading amount1Out:  %w", err)
	}
	f5, err := dec.ReadTypedTopic("address")
	if err != nil {
		return nil, fmt.Errorf("reading to: %w", err)
	}
	ev.To = f5.(eth.Address)
	return ev, nil
}

// PairSync event

type PairSyncEvent struct {
	*entity.BaseEvent
	LogAddress eth.Address
	LogIndex   int

	// Fields
	Reserve0 *big.Int `eth:""`
	Reserve1 *big.Int `eth:""`
}

var hashPairSyncEvent = eth.Keccak256([]byte("Sync(uint112,uint112)"))

func IsPairSyncEvent(log *eth.Log) bool {
	return bytes.Equal(log.Topics[0], hashPairSyncEvent)
}

func NewPairSyncEvent(log *eth.Log, block *pbcodec.Block, trace *pbcodec.TransactionTrace) (*PairSyncEvent, error) {
	var err error
	ev := &PairSyncEvent{
		BaseEvent:  &entity.BaseEvent{},
		LogAddress: log.Address,
		LogIndex:   int(log.BlockIndex),
	}

	ev.SetBlockAndTransaction(block, trace)

	dec := eth.NewLogDecoder(log)
	if _, err := dec.ReadTopic(); err != nil {
		return nil, fmt.Errorf("reading topic 0: %w", err)
	}
	ev.Reserve0, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading reserve0:  %w", err)
	}
	ev.Reserve1, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading reserve1:  %w", err)
	}
	return ev, nil
}

// PairTransfer event

type PairTransferEvent struct {
	*entity.BaseEvent
	LogAddress eth.Address
	LogIndex   int

	// Fields
	From  eth.Address `eth:",indexed"`
	To    eth.Address `eth:",indexed"`
	Value *big.Int    `eth:""`
}

var hashPairTransferEvent = eth.Keccak256([]byte("Transfer(address,address,uint256)"))

func IsPairTransferEvent(log *eth.Log) bool {
	return bytes.Equal(log.Topics[0], hashPairTransferEvent)
}

func NewPairTransferEvent(log *eth.Log, block *pbcodec.Block, trace *pbcodec.TransactionTrace) (*PairTransferEvent, error) {
	var err error
	ev := &PairTransferEvent{
		BaseEvent:  &entity.BaseEvent{},
		LogAddress: log.Address,
		LogIndex:   int(log.BlockIndex),
	}

	ev.SetBlockAndTransaction(block, trace)

	dec := eth.NewLogDecoder(log)
	if _, err := dec.ReadTopic(); err != nil {
		return nil, fmt.Errorf("reading topic 0: %w", err)
	}
	f0, err := dec.ReadTypedTopic("address")
	if err != nil {
		return nil, fmt.Errorf("reading from: %w", err)
	}
	ev.From = f0.(eth.Address)
	f1, err := dec.ReadTypedTopic("address")
	if err != nil {
		return nil, fmt.Errorf("reading to: %w", err)
	}
	ev.To = f1.(eth.Address)
	ev.Value, err = dec.DataDecoder.ReadBigInt()
	if err != nil {
		return nil, fmt.Errorf("reading value:  %w", err)
	}
	return ev, nil
}

func DecodeEvent(log *eth.Log, block *pbcodec.Block, trace *pbcodec.TransactionTrace) (interface{}, error) {

	if IsFactoryPairCreatedEvent(log) {
		ev, err := NewFactoryPairCreatedEvent(log, block, trace)
		if err != nil {
			return nil, fmt.Errorf("decoding FactoryPairCreated event: %w", err)
		}
		return ev, nil
	}

	if IsPairApprovalEvent(log) {
		ev, err := NewPairApprovalEvent(log, block, trace)
		if err != nil {
			return nil, fmt.Errorf("decoding PairApproval event: %w", err)
		}
		return ev, nil
	}
	if IsPairBurnEvent(log) {
		ev, err := NewPairBurnEvent(log, block, trace)
		if err != nil {
			return nil, fmt.Errorf("decoding PairBurn event: %w", err)
		}
		return ev, nil
	}
	if IsPairMintEvent(log) {
		ev, err := NewPairMintEvent(log, block, trace)
		if err != nil {
			return nil, fmt.Errorf("decoding PairMint event: %w", err)
		}
		return ev, nil
	}
	if IsPairSwapEvent(log) {
		ev, err := NewPairSwapEvent(log, block, trace)
		if err != nil {
			return nil, fmt.Errorf("decoding PairSwap event: %w", err)
		}
		return ev, nil
	}
	if IsPairSyncEvent(log) {
		ev, err := NewPairSyncEvent(log, block, trace)
		if err != nil {
			return nil, fmt.Errorf("decoding PairSync event: %w", err)
		}
		return ev, nil
	}
	if IsPairTransferEvent(log) {
		ev, err := NewPairTransferEvent(log, block, trace)
		if err != nil {
			return nil, fmt.Errorf("decoding PairTransfer event: %w", err)
		}
		return ev, nil
	}

	return nil, nil
}

type DynamicDataSourceXXX struct {
	entity.Base

	Context string `db:"context" csv:"context"`
	ABI     string `db:"abi" csv:"abi"`
}

func NewDynamicDataSource(id string, abi string, context string) *DynamicDataSourceXXX {
	return &DynamicDataSourceXXX{
		Base:    entity.NewBase(id),
		Context: context,
		ABI:     abi,
	}
}
func (s *Subgraph) CreatePairTemplate(address eth.Address, obj interface{}) error {
	cnt, err := json.Marshal(obj)
	if err != nil {
		return err
	}

	ds := NewDynamicDataSource(address.Pretty(), "Pair", string(cnt))

	if err := s.Save(ds); err != nil {
		return fmt.Errorf("saving Pair datasource: %w", err)
	}

	s.CurrentBlockDynamicDataSources[address.Pretty()] = ds

	return nil
}

func (s *Subgraph) IsDynamicDataSource(address string) bool {
	_, ok := s.DynamicDataSources[address]
	return ok
}

func (s *Subgraph) IsCurrentDynamicDataSource(address string) bool {
	_, ok := s.CurrentBlockDynamicDataSources[address]
	return ok
}

func (s *Subgraph) LoadDynamicDataSources(blockNum uint64) error {
	res, err := s.LoadAllDistinct(&DynamicDataSourceXXX{}, blockNum)
	if err != nil {
		return fmt.Errorf("loading dynamic data sources: %w", err)
	}
	for _, dsi := range res {
		ds := dsi.(*DynamicDataSourceXXX)
		if ds.ABI == "Pair" {
			s.DynamicDataSources[ds.GetID()] = ds
		}
	}
	return nil
}

type DDL struct {
	createTables map[string]string
	indexes      map[string][]*index
	schemaSetup  string
}

var ddl *DDL

type index struct {
	createStatement string
	dropStatement   string
}

var createTables = map[string]string{}
var indexes = map[string][]*index{}

func init() {
	ddl = &DDL{
		createTables: map[string]string{},
		indexes:      map[string][]*index{},
	}

	Definition.DDL = ddl

	ddl.createTables["user"] = `
create table if not exists %%SCHEMA%%.user
(
	id text not null,

	vid bigserial not null constraint user_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.user owner to graph;
alter sequence %%SCHEMA%%.user_vid_seq owned by %%SCHEMA%%.user.vid;
alter table only %%SCHEMA%%.user alter column vid SET DEFAULT nextval('%%SCHEMA%%.user_vid_seq'::regclass);
`

	ddl.createTables["bundle"] = `
create table if not exists %%SCHEMA%%.bundle
(
	id text not null,

	"eth_price" numeric not null,

	vid bigserial not null constraint bundle_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.bundle owner to graph;
alter sequence %%SCHEMA%%.bundle_vid_seq owned by %%SCHEMA%%.bundle.vid;
alter table only %%SCHEMA%%.bundle alter column vid SET DEFAULT nextval('%%SCHEMA%%.bundle_vid_seq'::regclass);
`

	ddl.createTables["factory"] = `
create table if not exists %%SCHEMA%%.factory
(
	id text not null,

	"pair_count" numeric not null,

	"volume_usd" numeric not null,

	"volume_eth" numeric not null,

	"untracked_volume_usd" numeric not null,

	"liquidity_usd" numeric not null,

	"liquidity_eth" numeric not null,

	"tx_count" numeric not null,

	"token_count" numeric not null,

	"user_count" numeric not null,

	vid bigserial not null constraint factory_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.factory owner to graph;
alter sequence %%SCHEMA%%.factory_vid_seq owned by %%SCHEMA%%.factory.vid;
alter table only %%SCHEMA%%.factory alter column vid SET DEFAULT nextval('%%SCHEMA%%.factory_vid_seq'::regclass);
`

	ddl.createTables["hour_data"] = `
create table if not exists %%SCHEMA%%.hour_data
(
	id text not null,

	"date" numeric not null,

	"factory" text not null,

	"volume_eth" numeric not null,

	"volume_usd" numeric not null,

	"untracked_volume" numeric not null,

	"liquidity_eth" numeric not null,

	"liquidity_usd" numeric not null,

	"tx_count" numeric not null,

	vid bigserial not null constraint hour_data_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.hour_data owner to graph;
alter sequence %%SCHEMA%%.hour_data_vid_seq owned by %%SCHEMA%%.hour_data.vid;
alter table only %%SCHEMA%%.hour_data alter column vid SET DEFAULT nextval('%%SCHEMA%%.hour_data_vid_seq'::regclass);
`

	ddl.createTables["day_data"] = `
create table if not exists %%SCHEMA%%.day_data
(
	id text not null,

	"date" numeric not null,

	"factory" text not null,

	"volume_eth" numeric not null,

	"volume_usd" numeric not null,

	"untracked_volume" numeric not null,

	"liquidity_eth" numeric not null,

	"liquidity_usd" numeric not null,

	"tx_count" numeric not null,

	vid bigserial not null constraint day_data_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.day_data owner to graph;
alter sequence %%SCHEMA%%.day_data_vid_seq owned by %%SCHEMA%%.day_data.vid;
alter table only %%SCHEMA%%.day_data alter column vid SET DEFAULT nextval('%%SCHEMA%%.day_data_vid_seq'::regclass);
`

	ddl.createTables["token"] = `
create table if not exists %%SCHEMA%%.token
(
	id text not null,

	"factory" text not null,

	"symbol" text not null,

	"name" text not null,

	"decimals" numeric not null,

	"total_supply" numeric not null,

	"volume" numeric not null,

	"volume_usd" numeric not null,

	"untracked_volume_usd" numeric not null,

	"tx_count" numeric not null,

	"liquidity" numeric not null,

	"derived_eth" numeric not null,

	"whitelist_pairs" text[] not null,

	vid bigserial not null constraint token_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.token owner to graph;
alter sequence %%SCHEMA%%.token_vid_seq owned by %%SCHEMA%%.token.vid;
alter table only %%SCHEMA%%.token alter column vid SET DEFAULT nextval('%%SCHEMA%%.token_vid_seq'::regclass);
`

	ddl.createTables["token_hour_data"] = `
create table if not exists %%SCHEMA%%.token_hour_data
(
	id text not null,

	"date" numeric not null,

	"token" text not null,

	"volume" numeric not null,

	"volume_eth" numeric not null,

	"volume_usd" numeric not null,

	"tx_count" numeric not null,

	"liquidity" numeric not null,

	"liquidity_eth" numeric not null,

	"liquidity_usd" numeric not null,

	"price_usd" numeric not null,

	vid bigserial not null constraint token_hour_data_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.token_hour_data owner to graph;
alter sequence %%SCHEMA%%.token_hour_data_vid_seq owned by %%SCHEMA%%.token_hour_data.vid;
alter table only %%SCHEMA%%.token_hour_data alter column vid SET DEFAULT nextval('%%SCHEMA%%.token_hour_data_vid_seq'::regclass);
`

	ddl.createTables["token_day_data"] = `
create table if not exists %%SCHEMA%%.token_day_data
(
	id text not null,

	"date" numeric not null,

	"token" text not null,

	"volume" numeric not null,

	"volume_eth" numeric not null,

	"volume_usd" numeric not null,

	"tx_count" numeric not null,

	"liquidity" numeric not null,

	"liquidity_eth" numeric not null,

	"liquidity_usd" numeric not null,

	"price_usd" numeric not null,

	vid bigserial not null constraint token_day_data_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.token_day_data owner to graph;
alter sequence %%SCHEMA%%.token_day_data_vid_seq owned by %%SCHEMA%%.token_day_data.vid;
alter table only %%SCHEMA%%.token_day_data alter column vid SET DEFAULT nextval('%%SCHEMA%%.token_day_data_vid_seq'::regclass);
`

	ddl.createTables["pair"] = `
create table if not exists %%SCHEMA%%.pair
(
	id text not null,

	"factory" text not null,

	"name" text not null,

	"token_0" text not null,

	"token_1" text not null,

	"reserve_0" numeric not null,

	"reserve_1" numeric not null,

	"total_supply" numeric not null,

	"reserve_eth" numeric not null,

	"reserve_usd" numeric not null,

	"tracked_reserve_eth" numeric not null,

	"token_0_price" numeric not null,

	"token_1_price" numeric not null,

	"volume_token_0" numeric not null,

	"volume_token_1" numeric not null,

	"volume_usd" numeric not null,

	"untracked_volume_usd" numeric not null,

	"tx_count" numeric not null,

	"liquidity_provider_count" numeric not null,

	"timestamp" numeric not null,

	"block" numeric not null,

	vid bigserial not null constraint pair_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.pair owner to graph;
alter sequence %%SCHEMA%%.pair_vid_seq owned by %%SCHEMA%%.pair.vid;
alter table only %%SCHEMA%%.pair alter column vid SET DEFAULT nextval('%%SCHEMA%%.pair_vid_seq'::regclass);
`

	ddl.createTables["pair_hour_data"] = `
create table if not exists %%SCHEMA%%.pair_hour_data
(
	id text not null,

	"date" numeric not null,

	"pair" text not null,

	"reserve_0" numeric not null,

	"reserve_1" numeric not null,

	"reserve_usd" numeric not null,

	"volume_token_0" numeric not null,

	"volume_token_1" numeric not null,

	"volume_usd" numeric not null,

	"tx_count" numeric not null,

	vid bigserial not null constraint pair_hour_data_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.pair_hour_data owner to graph;
alter sequence %%SCHEMA%%.pair_hour_data_vid_seq owned by %%SCHEMA%%.pair_hour_data.vid;
alter table only %%SCHEMA%%.pair_hour_data alter column vid SET DEFAULT nextval('%%SCHEMA%%.pair_hour_data_vid_seq'::regclass);
`

	ddl.createTables["pair_day_data"] = `
create table if not exists %%SCHEMA%%.pair_day_data
(
	id text not null,

	"date" numeric not null,

	"pair" text not null,

	"token_0" text not null,

	"token_1" text not null,

	"reserve_0" numeric not null,

	"reserve_1" numeric not null,

	"total_supply" numeric not null,

	"reserve_usd" numeric not null,

	"volume_token_0" numeric not null,

	"volume_token_1" numeric not null,

	"volume_usd" numeric not null,

	"tx_count" numeric not null,

	vid bigserial not null constraint pair_day_data_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.pair_day_data owner to graph;
alter sequence %%SCHEMA%%.pair_day_data_vid_seq owned by %%SCHEMA%%.pair_day_data.vid;
alter table only %%SCHEMA%%.pair_day_data alter column vid SET DEFAULT nextval('%%SCHEMA%%.pair_day_data_vid_seq'::regclass);
`

	ddl.createTables["liquidity_position"] = `
create table if not exists %%SCHEMA%%.liquidity_position
(
	id text not null,

	"user" text not null,

	"pair" text not null,

	"liquidity_token_balance" numeric not null,

	"block" numeric not null,

	"timestamp" numeric not null,

	vid bigserial not null constraint liquidity_position_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.liquidity_position owner to graph;
alter sequence %%SCHEMA%%.liquidity_position_vid_seq owned by %%SCHEMA%%.liquidity_position.vid;
alter table only %%SCHEMA%%.liquidity_position alter column vid SET DEFAULT nextval('%%SCHEMA%%.liquidity_position_vid_seq'::regclass);
`

	ddl.createTables["liquidity_position_snapshot"] = `
create table if not exists %%SCHEMA%%.liquidity_position_snapshot
(
	id text not null,

	"liquidity_position" text not null,

	"timestamp" numeric not null,

	"block" numeric not null,

	"user" text not null,

	"pair" text not null,

	"token_0_price_usd" numeric not null,

	"token_1_price_usd" numeric not null,

	"reserve_0" numeric not null,

	"reserve_1" numeric not null,

	"reserve_usd" numeric not null,

	"liquidity_token_total_supply" numeric not null,

	"liquidity_token_balance" numeric not null,

	vid bigserial not null constraint liquidity_position_snapshot_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.liquidity_position_snapshot owner to graph;
alter sequence %%SCHEMA%%.liquidity_position_snapshot_vid_seq owned by %%SCHEMA%%.liquidity_position_snapshot.vid;
alter table only %%SCHEMA%%.liquidity_position_snapshot alter column vid SET DEFAULT nextval('%%SCHEMA%%.liquidity_position_snapshot_vid_seq'::regclass);
`

	ddl.createTables["transaction"] = `
create table if not exists %%SCHEMA%%.transaction
(
	id text not null,

	"block_number" numeric not null,

	"timestamp" numeric not null,

	"mints" text[],

	"burns" text[],

	"swaps" text[],

	vid bigserial not null constraint transaction_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.transaction owner to graph;
alter sequence %%SCHEMA%%.transaction_vid_seq owned by %%SCHEMA%%.transaction.vid;
alter table only %%SCHEMA%%.transaction alter column vid SET DEFAULT nextval('%%SCHEMA%%.transaction_vid_seq'::regclass);
`

	ddl.createTables["mint"] = `
create table if not exists %%SCHEMA%%.mint
(
	id text not null,

	"transaction" text not null,

	"timestamp" numeric not null,

	"pair" text not null,

	"to" text not null,

	"liquidity" numeric not null,

	"sender" text,

	"amount_0" numeric,

	"amount_1" numeric,

	"log_index" numeric,

	"amount_usd" numeric,

	"fee_to" text,

	"fee_liquidity" numeric,

	vid bigserial not null constraint mint_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.mint owner to graph;
alter sequence %%SCHEMA%%.mint_vid_seq owned by %%SCHEMA%%.mint.vid;
alter table only %%SCHEMA%%.mint alter column vid SET DEFAULT nextval('%%SCHEMA%%.mint_vid_seq'::regclass);
`

	ddl.createTables["burn"] = `
create table if not exists %%SCHEMA%%.burn
(
	id text not null,

	"transaction" text not null,

	"timestamp" numeric not null,

	"pair" text not null,

	"liquidity" numeric not null,

	"sender" text,

	"amount_0" numeric,

	"amount_1" numeric,

	"to" text,

	"log_index" numeric,

	"amount_usd" numeric,

	"complete" boolean not null,

	"fee_to" text,

	"fee_liquidity" numeric,

	vid bigserial not null constraint burn_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.burn owner to graph;
alter sequence %%SCHEMA%%.burn_vid_seq owned by %%SCHEMA%%.burn.vid;
alter table only %%SCHEMA%%.burn alter column vid SET DEFAULT nextval('%%SCHEMA%%.burn_vid_seq'::regclass);
`

	ddl.createTables["swap"] = `
create table if not exists %%SCHEMA%%.swap
(
	id text not null,

	"transaction" text not null,

	"timestamp" numeric not null,

	"pair" text not null,

	"sender" text not null,

	"amount_0_in" numeric not null,

	"amount_1_in" numeric not null,

	"amount_0_out" numeric not null,

	"amount_1_out" numeric not null,

	"to" text not null,

	"log_index" numeric,

	"amount_usd" numeric not null,

	vid bigserial not null constraint swap_pkey primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.swap owner to graph;
alter sequence %%SCHEMA%%.swap_vid_seq owned by %%SCHEMA%%.swap.vid;
alter table only %%SCHEMA%%.swap alter column vid SET DEFAULT nextval('%%SCHEMA%%.swap_vid_seq'::regclass);
`

	ddl.indexes["user"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists user_block_range_closed on %%SCHEMA%%.user (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.user_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists user_id on %%SCHEMA%%.user (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.user_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists user_updated_block_number on %%SCHEMA%%.user (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.user_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists user_id_block_range_fake_excl on %%SCHEMA%%.user using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.user_id_block_range_fake_excl;`,
		})

		return indexes
	}()

	ddl.indexes["bundle"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists bundle_block_range_closed on %%SCHEMA%%.bundle (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.bundle_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists bundle_id on %%SCHEMA%%.bundle (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.bundle_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists bundle_updated_block_number on %%SCHEMA%%.bundle (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.bundle_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists bundle_id_block_range_fake_excl on %%SCHEMA%%.bundle using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.bundle_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists bundle_eth_price on %%SCHEMA%%.bundle using btree ("eth_price");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.bundle_eth_price;`,
		})

		return indexes
	}()

	ddl.indexes["factory"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_block_range_closed on %%SCHEMA%%.factory (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_id on %%SCHEMA%%.factory (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_updated_block_number on %%SCHEMA%%.factory (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_id_block_range_fake_excl on %%SCHEMA%%.factory using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_pair_count on %%SCHEMA%%.factory using btree ("pair_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_pair_count;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_volume_usd on %%SCHEMA%%.factory using btree ("volume_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_volume_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_volume_eth on %%SCHEMA%%.factory using btree ("volume_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_volume_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_untracked_volume_usd on %%SCHEMA%%.factory using btree ("untracked_volume_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_untracked_volume_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_liquidity_usd on %%SCHEMA%%.factory using btree ("liquidity_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_liquidity_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_liquidity_eth on %%SCHEMA%%.factory using btree ("liquidity_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_liquidity_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_tx_count on %%SCHEMA%%.factory using btree ("tx_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_tx_count;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_token_count on %%SCHEMA%%.factory using btree ("token_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_token_count;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists factory_user_count on %%SCHEMA%%.factory using btree ("user_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.factory_user_count;`,
		})

		return indexes
	}()

	ddl.indexes["hour_data"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_block_range_closed on %%SCHEMA%%.hour_data (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_id on %%SCHEMA%%.hour_data (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_updated_block_number on %%SCHEMA%%.hour_data (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_id_block_range_fake_excl on %%SCHEMA%%.hour_data using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_date on %%SCHEMA%%.hour_data using btree ("date");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_date;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_factory on %%SCHEMA%%.hour_data using gist ("factory", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_factory;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_volume_eth on %%SCHEMA%%.hour_data using btree ("volume_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_volume_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_volume_usd on %%SCHEMA%%.hour_data using btree ("volume_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_volume_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_untracked_volume on %%SCHEMA%%.hour_data using btree ("untracked_volume");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_untracked_volume;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_liquidity_eth on %%SCHEMA%%.hour_data using btree ("liquidity_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_liquidity_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_liquidity_usd on %%SCHEMA%%.hour_data using btree ("liquidity_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_liquidity_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists hour_data_tx_count on %%SCHEMA%%.hour_data using btree ("tx_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.hour_data_tx_count;`,
		})

		return indexes
	}()

	ddl.indexes["day_data"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_block_range_closed on %%SCHEMA%%.day_data (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_id on %%SCHEMA%%.day_data (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_updated_block_number on %%SCHEMA%%.day_data (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_id_block_range_fake_excl on %%SCHEMA%%.day_data using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_date on %%SCHEMA%%.day_data using btree ("date");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_date;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_factory on %%SCHEMA%%.day_data using gist ("factory", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_factory;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_volume_eth on %%SCHEMA%%.day_data using btree ("volume_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_volume_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_volume_usd on %%SCHEMA%%.day_data using btree ("volume_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_volume_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_untracked_volume on %%SCHEMA%%.day_data using btree ("untracked_volume");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_untracked_volume;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_liquidity_eth on %%SCHEMA%%.day_data using btree ("liquidity_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_liquidity_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_liquidity_usd on %%SCHEMA%%.day_data using btree ("liquidity_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_liquidity_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists day_data_tx_count on %%SCHEMA%%.day_data using btree ("tx_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.day_data_tx_count;`,
		})

		return indexes
	}()

	ddl.indexes["token"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_block_range_closed on %%SCHEMA%%.token (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_id on %%SCHEMA%%.token (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_updated_block_number on %%SCHEMA%%.token (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_id_block_range_fake_excl on %%SCHEMA%%.token using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_factory on %%SCHEMA%%.token using gist ("factory", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_factory;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_symbol on %%SCHEMA%%.token ("left"("symbol", 256));`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_symbol;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_name on %%SCHEMA%%.token ("left"("name", 256));`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_name;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_decimals on %%SCHEMA%%.token using btree ("decimals");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_decimals;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_total_supply on %%SCHEMA%%.token using btree ("total_supply");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_total_supply;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_volume on %%SCHEMA%%.token using btree ("volume");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_volume;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_untracked_volume_usd on %%SCHEMA%%.token using btree ("untracked_volume_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_untracked_volume_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_tx_count on %%SCHEMA%%.token using btree ("tx_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_tx_count;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_liquidity on %%SCHEMA%%.token using btree ("liquidity");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_liquidity;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_derived_eth on %%SCHEMA%%.token using btree ("derived_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_derived_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_whitelist_pairs on %%SCHEMA%%.token using gin (whitelist_pairs);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_whitelist_pairs;`,
		})

		return indexes
	}()

	ddl.indexes["token_hour_data"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_block_range_closed on %%SCHEMA%%.token_hour_data (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_id on %%SCHEMA%%.token_hour_data (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_updated_block_number on %%SCHEMA%%.token_hour_data (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_id_block_range_fake_excl on %%SCHEMA%%.token_hour_data using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_date on %%SCHEMA%%.token_hour_data using btree ("date");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_date;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_token on %%SCHEMA%%.token_hour_data using gist ("token", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_token;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_volume on %%SCHEMA%%.token_hour_data using btree ("volume");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_volume;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_volume_eth on %%SCHEMA%%.token_hour_data using btree ("volume_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_volume_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_volume_usd on %%SCHEMA%%.token_hour_data using btree ("volume_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_volume_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_tx_count on %%SCHEMA%%.token_hour_data using btree ("tx_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_tx_count;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_liquidity on %%SCHEMA%%.token_hour_data using btree ("liquidity");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_liquidity;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_liquidity_eth on %%SCHEMA%%.token_hour_data using btree ("liquidity_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_liquidity_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_liquidity_usd on %%SCHEMA%%.token_hour_data using btree ("liquidity_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_liquidity_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_hour_data_price_usd on %%SCHEMA%%.token_hour_data using btree ("price_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_hour_data_price_usd;`,
		})

		return indexes
	}()

	ddl.indexes["token_day_data"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_block_range_closed on %%SCHEMA%%.token_day_data (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_id on %%SCHEMA%%.token_day_data (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_updated_block_number on %%SCHEMA%%.token_day_data (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_id_block_range_fake_excl on %%SCHEMA%%.token_day_data using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_date on %%SCHEMA%%.token_day_data using btree ("date");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_date;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_token on %%SCHEMA%%.token_day_data using gist ("token", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_token;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_volume on %%SCHEMA%%.token_day_data using btree ("volume");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_volume;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_volume_eth on %%SCHEMA%%.token_day_data using btree ("volume_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_volume_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_volume_usd on %%SCHEMA%%.token_day_data using btree ("volume_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_volume_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_tx_count on %%SCHEMA%%.token_day_data using btree ("tx_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_tx_count;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_liquidity on %%SCHEMA%%.token_day_data using btree ("liquidity");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_liquidity;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_liquidity_eth on %%SCHEMA%%.token_day_data using btree ("liquidity_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_liquidity_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_liquidity_usd on %%SCHEMA%%.token_day_data using btree ("liquidity_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_liquidity_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists token_day_data_price_usd on %%SCHEMA%%.token_day_data using btree ("price_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.token_day_data_price_usd;`,
		})

		return indexes
	}()

	ddl.indexes["pair"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_block_range_closed on %%SCHEMA%%.pair (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_id on %%SCHEMA%%.pair (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_updated_block_number on %%SCHEMA%%.pair (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_id_block_range_fake_excl on %%SCHEMA%%.pair using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_factory on %%SCHEMA%%.pair using gist ("factory", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_factory;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_name on %%SCHEMA%%.pair ("left"("name", 256));`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_name;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_token_0 on %%SCHEMA%%.pair using gist ("token_0", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_token_0;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_token_1 on %%SCHEMA%%.pair using gist ("token_1", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_token_1;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_reserve_0 on %%SCHEMA%%.pair using btree ("reserve_0");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_reserve_0;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_reserve_1 on %%SCHEMA%%.pair using btree ("reserve_1");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_reserve_1;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_total_supply on %%SCHEMA%%.pair using btree ("total_supply");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_total_supply;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_reserve_eth on %%SCHEMA%%.pair using btree ("reserve_eth");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_reserve_eth;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_token_0_price on %%SCHEMA%%.pair using btree ("token_0_price");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_token_0_price;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_token_1_price on %%SCHEMA%%.pair using btree ("token_1_price");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_token_1_price;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_volume_token_0 on %%SCHEMA%%.pair using btree ("volume_token_0");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_volume_token_0;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_volume_token_1 on %%SCHEMA%%.pair using btree ("volume_token_1");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_volume_token_1;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_untracked_volume_usd on %%SCHEMA%%.pair using btree ("untracked_volume_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_untracked_volume_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_tx_count on %%SCHEMA%%.pair using btree ("tx_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_tx_count;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_liquidity_provider_count on %%SCHEMA%%.pair using btree ("liquidity_provider_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_liquidity_provider_count;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_timestamp on %%SCHEMA%%.pair using btree ("timestamp");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_timestamp;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_block on %%SCHEMA%%.pair using btree ("block");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_block;`,
		})

		return indexes
	}()

	ddl.indexes["pair_hour_data"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_block_range_closed on %%SCHEMA%%.pair_hour_data (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_id on %%SCHEMA%%.pair_hour_data (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_updated_block_number on %%SCHEMA%%.pair_hour_data (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_id_block_range_fake_excl on %%SCHEMA%%.pair_hour_data using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_date on %%SCHEMA%%.pair_hour_data using btree ("date");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_date;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_pair on %%SCHEMA%%.pair_hour_data using gist ("pair", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_pair;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_reserve_0 on %%SCHEMA%%.pair_hour_data using btree ("reserve_0");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_reserve_0;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_reserve_1 on %%SCHEMA%%.pair_hour_data using btree ("reserve_1");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_reserve_1;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_reserve_usd on %%SCHEMA%%.pair_hour_data using btree ("reserve_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_reserve_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_volume_token_0 on %%SCHEMA%%.pair_hour_data using btree ("volume_token_0");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_volume_token_0;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_volume_token_1 on %%SCHEMA%%.pair_hour_data using btree ("volume_token_1");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_volume_token_1;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_volume_usd on %%SCHEMA%%.pair_hour_data using btree ("volume_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_volume_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_hour_data_tx_count on %%SCHEMA%%.pair_hour_data using btree ("tx_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_hour_data_tx_count;`,
		})

		return indexes
	}()

	ddl.indexes["pair_day_data"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_block_range_closed on %%SCHEMA%%.pair_day_data (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_id on %%SCHEMA%%.pair_day_data (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_updated_block_number on %%SCHEMA%%.pair_day_data (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_id_block_range_fake_excl on %%SCHEMA%%.pair_day_data using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_date on %%SCHEMA%%.pair_day_data using btree ("date");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_date;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_pair on %%SCHEMA%%.pair_day_data using gist ("pair", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_pair;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_token_0 on %%SCHEMA%%.pair_day_data using gist ("token_0", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_token_0;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_token_1 on %%SCHEMA%%.pair_day_data using gist ("token_1", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_token_1;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_reserve_0 on %%SCHEMA%%.pair_day_data using btree ("reserve_0");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_reserve_0;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_reserve_1 on %%SCHEMA%%.pair_day_data using btree ("reserve_1");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_reserve_1;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_total_supply on %%SCHEMA%%.pair_day_data using btree ("total_supply");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_total_supply;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_reserve_usd on %%SCHEMA%%.pair_day_data using btree ("reserve_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_reserve_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_volume_token_0 on %%SCHEMA%%.pair_day_data using btree ("volume_token_0");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_volume_token_0;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_volume_token_1 on %%SCHEMA%%.pair_day_data using btree ("volume_token_1");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_volume_token_1;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_volume_usd on %%SCHEMA%%.pair_day_data using btree ("volume_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_volume_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists pair_day_data_tx_count on %%SCHEMA%%.pair_day_data using btree ("tx_count");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.pair_day_data_tx_count;`,
		})

		return indexes
	}()

	ddl.indexes["liquidity_position"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_block_range_closed on %%SCHEMA%%.liquidity_position (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_id on %%SCHEMA%%.liquidity_position (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_updated_block_number on %%SCHEMA%%.liquidity_position (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_id_block_range_fake_excl on %%SCHEMA%%.liquidity_position using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_user on %%SCHEMA%%.liquidity_position using gist ("user", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_user;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_pair on %%SCHEMA%%.liquidity_position using gist ("pair", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_pair;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_liquidity_token_balance on %%SCHEMA%%.liquidity_position using btree ("liquidity_token_balance");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_liquidity_token_balance;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_block on %%SCHEMA%%.liquidity_position using btree ("block");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_block;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_timestamp on %%SCHEMA%%.liquidity_position using btree ("timestamp");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_timestamp;`,
		})

		return indexes
	}()

	ddl.indexes["liquidity_position_snapshot"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_block_range_closed on %%SCHEMA%%.liquidity_position_snapshot (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_id on %%SCHEMA%%.liquidity_position_snapshot (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_updated_block_number on %%SCHEMA%%.liquidity_position_snapshot (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_id_block_range_fake_excl on %%SCHEMA%%.liquidity_position_snapshot using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_liquidity_position on %%SCHEMA%%.liquidity_position_snapshot using gist ("liquidity_position", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_liquidity_position;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_timestamp on %%SCHEMA%%.liquidity_position_snapshot using btree ("timestamp");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_timestamp;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_block on %%SCHEMA%%.liquidity_position_snapshot using btree ("block");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_block;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_user on %%SCHEMA%%.liquidity_position_snapshot using gist ("user", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_user;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_pair on %%SCHEMA%%.liquidity_position_snapshot using gist ("pair", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_pair;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_token_0_price_usd on %%SCHEMA%%.liquidity_position_snapshot using btree ("token_0_price_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_token_0_price_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_token_1_price_usd on %%SCHEMA%%.liquidity_position_snapshot using btree ("token_1_price_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_token_1_price_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_reserve_0 on %%SCHEMA%%.liquidity_position_snapshot using btree ("reserve_0");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_reserve_0;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_reserve_1 on %%SCHEMA%%.liquidity_position_snapshot using btree ("reserve_1");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_reserve_1;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_reserve_usd on %%SCHEMA%%.liquidity_position_snapshot using btree ("reserve_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_reserve_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_liquidity_token_total_supply on %%SCHEMA%%.liquidity_position_snapshot using btree ("liquidity_token_total_supply");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_liquidity_token_total_supply;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists liquidity_position_snapshot_liquidity_token_balance on %%SCHEMA%%.liquidity_position_snapshot using btree ("liquidity_token_balance");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.liquidity_position_snapshot_liquidity_token_balance;`,
		})

		return indexes
	}()

	ddl.indexes["transaction"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists transaction_block_range_closed on %%SCHEMA%%.transaction (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.transaction_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists transaction_id on %%SCHEMA%%.transaction (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.transaction_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists transaction_updated_block_number on %%SCHEMA%%.transaction (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.transaction_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists transaction_id_block_range_fake_excl on %%SCHEMA%%.transaction using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.transaction_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists transaction_block_number on %%SCHEMA%%.transaction using btree ("block_number");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.transaction_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists transaction_timestamp on %%SCHEMA%%.transaction using btree ("timestamp");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.transaction_timestamp;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists transaction_mints on %%SCHEMA%%.transaction using gin (mints);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.transaction_mints;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists transaction_burns on %%SCHEMA%%.transaction using gin (burns);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.transaction_burns;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists transaction_swaps on %%SCHEMA%%.transaction using gin (swaps);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.transaction_swaps;`,
		})

		return indexes
	}()

	ddl.indexes["mint"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_block_range_closed on %%SCHEMA%%.mint (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_id on %%SCHEMA%%.mint (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_updated_block_number on %%SCHEMA%%.mint (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_id_block_range_fake_excl on %%SCHEMA%%.mint using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_transaction on %%SCHEMA%%.mint using gist ("transaction", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_transaction;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_timestamp on %%SCHEMA%%.mint using btree ("timestamp");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_timestamp;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_pair on %%SCHEMA%%.mint using gist ("pair", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_pair;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_to on %%SCHEMA%%.mint ("left"("to", 256));`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_to;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_liquidity on %%SCHEMA%%.mint using btree ("liquidity");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_liquidity;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_sender on %%SCHEMA%%.mint ("left"("sender", 256));`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_sender;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_amount_0 on %%SCHEMA%%.mint using btree ("amount_0");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_amount_0;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_amount_1 on %%SCHEMA%%.mint using btree ("amount_1");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_amount_1;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_log_index on %%SCHEMA%%.mint using btree ("log_index");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_log_index;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_amount_usd on %%SCHEMA%%.mint using btree ("amount_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_amount_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_fee_to on %%SCHEMA%%.mint ("left"("fee_to", 256));`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_fee_to;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists mint_fee_liquidity on %%SCHEMA%%.mint using btree ("fee_liquidity");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.mint_fee_liquidity;`,
		})

		return indexes
	}()

	ddl.indexes["burn"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_block_range_closed on %%SCHEMA%%.burn (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_id on %%SCHEMA%%.burn (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_updated_block_number on %%SCHEMA%%.burn (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_id_block_range_fake_excl on %%SCHEMA%%.burn using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_transaction on %%SCHEMA%%.burn using gist ("transaction", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_transaction;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_timestamp on %%SCHEMA%%.burn using btree ("timestamp");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_timestamp;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_pair on %%SCHEMA%%.burn using gist ("pair", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_pair;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_liquidity on %%SCHEMA%%.burn using btree ("liquidity");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_liquidity;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_sender on %%SCHEMA%%.burn ("left"("sender", 256));`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_sender;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_amount_0 on %%SCHEMA%%.burn using btree ("amount_0");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_amount_0;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_amount_1 on %%SCHEMA%%.burn using btree ("amount_1");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_amount_1;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_to on %%SCHEMA%%.burn ("left"("to", 256));`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_to;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_log_index on %%SCHEMA%%.burn using btree ("log_index");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_log_index;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_amount_usd on %%SCHEMA%%.burn using btree ("amount_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_amount_usd;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_complete on %%SCHEMA%%.burn using btree ("complete");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_complete;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_fee_to on %%SCHEMA%%.burn ("left"("fee_to", 256));`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_fee_to;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists burn_fee_liquidity on %%SCHEMA%%.burn using btree ("fee_liquidity");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.burn_fee_liquidity;`,
		})

		return indexes
	}()

	ddl.indexes["swap"] = func() []*index {
		var indexes []*index
		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_block_range_closed on %%SCHEMA%%.swap (COALESCE(upper(block_range), 2147483647)) where (COALESCE(upper(block_range), 2147483647) < 2147483647);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_block_range_closed;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_id on %%SCHEMA%%.swap (id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_id;`,
		})
		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_updated_block_number on %%SCHEMA%%.swap (_updated_block_number);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_updated_block_number;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_id_block_range_fake_excl on %%SCHEMA%%.swap using gist (block_range, id);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_id_block_range_fake_excl;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_transaction on %%SCHEMA%%.swap using gist ("transaction", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_transaction;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_timestamp on %%SCHEMA%%.swap using btree ("timestamp");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_timestamp;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_pair on %%SCHEMA%%.swap using gist ("pair", block_range);`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_pair;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_sender on %%SCHEMA%%.swap ("left"("sender", 256));`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_sender;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_amount_0_in on %%SCHEMA%%.swap using btree ("amount_0_in");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_amount_0_in;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_amount_1_in on %%SCHEMA%%.swap using btree ("amount_1_in");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_amount_1_in;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_amount_0_out on %%SCHEMA%%.swap using btree ("amount_0_out");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_amount_0_out;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_amount_1_out on %%SCHEMA%%.swap using btree ("amount_1_out");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_amount_1_out;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_to on %%SCHEMA%%.swap ("left"("to", 256));`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_to;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_log_index on %%SCHEMA%%.swap using btree ("log_index");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_log_index;`,
		})

		indexes = append(indexes, &index{
			createStatement: `create index if not exists swap_amount_usd on %%SCHEMA%%.swap using btree ("amount_usd");`,
			dropStatement:   `drop index if exists %%SCHEMA%%.swap_amount_usd;`,
		})

		return indexes
	}()
	ddl.schemaSetup = `
CREATE SCHEMA if not exists %%SCHEMA%%;
DO
$do$
    BEGIN
        IF NOT EXISTS (
                SELECT FROM pg_catalog.pg_roles  -- SELECT list can be empty for this
                WHERE  rolname = 'graph') THEN
            CREATE ROLE graph;
        END IF;
    END
$do$;

set statement_timeout = 0;
set idle_in_transaction_session_timeout = 0;
set client_encoding = 'UTF8';
set standard_conforming_strings = on;
select pg_catalog.set_config('search_path', '', false);
set check_function_bodies = false;
set xmloption = content;
set client_min_messages = warning;
set row_security = off;

create extension if not exists btree_gist with schema %%SCHEMA%%;


create table if not exists %%SCHEMA%%.cursor
(
	id integer not null
		constraint cursor_pkey
			primary key,
	cursor text
);
alter table %%SCHEMA%%.cursor owner to graph;

create table %%SCHEMA%%.poi2$
(
    digest      bytea     not null,
    id          text      not null,
    vid         bigserial not null
        constraint poi2$_pkey
            primary key,
    block_range int4range not null,
	_updated_block_number  numeric not null,
    constraint poi2$_id_block_range_excl
        exclude using gist (id with =, block_range with &&)
);

alter table %%SCHEMA%%.poi2$
    owner to graph;

create index brin_poi2$
    on %%SCHEMA%%.poi2$ using brin (lower(block_range), COALESCE(upper(block_range), 2147483647), vid);

CREATE INDEX poi2$_updated_block_number
    ON %%SCHEMA%%.poi2$ USING btree
	(_updated_block_number ASC NULLS LAST)
	TABLESPACE pg_default;

create index poi2$_block_range_closed
    on %%SCHEMA%%.poi2$ (COALESCE(upper(block_range), 2147483647))
    where (COALESCE(upper(block_range), 2147483647) < 2147483647);

create index attr_12_0_poi2$_digest
    on %%SCHEMA%%.poi2$ (digest);

create index attr_12_1_poi2$_id
    on %%SCHEMA%%.poi2$ ("left"(id, 256));

create table if not exists %%SCHEMA%%.dynamic_data_source_xxx
(
	id text not null,
	context text not null,
	abi text not null,
	vid bigserial not null
		constraint dynamic_data_source_xxx_pkey
			primary key,
	block_range int4range not null,
	_updated_block_number numeric not null
);

alter table %%SCHEMA%%.dynamic_data_source_xxx owner to graph;

create index if not exists dynamic_data_source_xxx_block_range_closed
	on %%SCHEMA%%.dynamic_data_source_xxx (COALESCE(upper(block_range), 2147483647))
	where (COALESCE(upper(block_range), 2147483647) < 2147483647);

create index if not exists dynamic_data_source_xxx_id
	on %%SCHEMA%%.dynamic_data_source_xxx (id);

create index if not exists dynamic_data_source_xxx_abi
	on %%SCHEMA%%.dynamic_data_source_xxx (abi);

`

}

func (d *DDL) InitiateSchema(handleStatement func(statement string) error) error {
	err := handleStatement(d.schemaSetup)
	if err != nil {
		return fmt.Errorf("handle statement: %w", err)
	}
	return nil
}

func (d *DDL) CreateTables(handleStatement func(table string, statement string) error) error {
	for table, statement := range d.createTables {
		err := handleStatement(table, statement)
		if err != nil {
			return fmt.Errorf("handle statement: %w", err)
		}
	}
	return nil
}

func (d *DDL) CreateIndexes(handleStatement func(table string, statement string) error) error {
	for table, idxs := range d.indexes {
		for _, idx := range idxs {
			err := handleStatement(table, idx.createStatement)
			if err != nil {
				return fmt.Errorf("handle statement: %w", err)
			}
		}
	}
	return nil
}

func (d *DDL) DropIndexes(handleStatement func(table string, statement string) error) error {
	for table, idxs := range d.indexes {
		for _, idx := range idxs {
			err := handleStatement(table, idx.dropStatement)
			if err != nil {
				return fmt.Errorf("handle statement: %w", err)
			}
		}
	}
	return nil
}

var defaultTestTokens = map[string]*eth.Token{
	"0x00": {Address: []byte{0}, Name: "token.0.name", Symbol: "token.0.symbol", Decimals: 0, TotalSupply: big.NewInt(1000)},
	"0x01": {Address: []byte{1}, Name: "token.1.name", Symbol: "token.1.symbol", Decimals: 10, TotalSupply: big.NewInt(10000)},
	"0x02": {Address: []byte{2}, Name: "token.2.name", Symbol: "token.2.symbol", Decimals: 18, TotalSupply: big.NewInt(100000)},
}

func NewTestSubgraph(int subgraph.Intrinsics) *Subgraph {
	return &Subgraph{
		Base: subgraph.Base{
			Intrinsics: int,
			Definition: Definition,
			ID:         "testSubgraph",
			Log:        zlog,
		},
		CurrentBlockDynamicDataSources: map[string]*DynamicDataSourceXXX{},
		DynamicDataSources:             map[string]*DynamicDataSourceXXX{},
	}
}

type TestIntrinsics struct {
	tokens map[string]*eth.Token
	store  map[string]map[string]entity.Interface
	step   int
}

func NewTestIntrinsics(testCase *TestCase) *TestIntrinsics {
	i := &TestIntrinsics{
		tokens: make(map[string]*eth.Token),
		store:  make(map[string]map[string]entity.Interface),
		step:   99999,
	}

	if testCase != nil {
		i.initialize(testCase)
	}

	return i
}

func (i *TestIntrinsics) initialize(testCase *TestCase) {
	i.setStoreData(testCase.StoreData)
	i.setTokens(testCase.Tokens)
}

func (i *TestIntrinsics) setStoreData(ents []*TypedEntity) {
	for _, value := range ents {
		err := i.Save(value.Entity)
		if err != nil {
			panic(err)
		}
	}
}

func (i *TestIntrinsics) setTokens(tokens []*TokenInfo) {
	if len(tokens) == 0 {
		i.tokens = defaultTestTokens
		return
	}

	for _, tokenInfo := range tokens {
		token := &eth.Token{
			Name:        tokenInfo.Name,
			Symbol:      tokenInfo.Symbol,
			Address:     []byte{byte(tokenInfo.Address)},
			Decimals:    uint(tokenInfo.Decimals),
			TotalSupply: big.NewInt(int64(tokenInfo.TotalSupply)),
		}
		i.tokens[token.Address.Pretty()] = token
	}
}

func (i *TestIntrinsics) Save(e entity.Interface) error {
	tableName := entity.GetTableName(e)
	tbl, found := i.store[tableName]
	if !found {
		tbl = make(map[string]entity.Interface)
		i.store[tableName] = tbl
	}

	e.SetExists(true)
	e.SetMutated(i.step)

	tbl[e.GetID()] = e
	return nil
}

func (i *TestIntrinsics) Load(e entity.Interface) error {
	tableName := entity.GetTableName(e)
	tbl, found := i.store[tableName]
	if !found {
		return nil
	}

	id := e.GetID()
	cachedEntity, found := tbl[id]
	if found {
		if cachedEntity == nil {
			return nil
		}
		ve := reflect.ValueOf(e).Elem()
		ve.Set(reflect.ValueOf(cachedEntity).Elem())
		return nil
	}

	return nil
}

func (i *TestIntrinsics) LoadAllDistinct(e entity.Interface, blockNum uint64) ([]entity.Interface, error) {
	result := make([]entity.Interface, 0)

	tableName := entity.GetTableName(e)
	tbl, found := i.store[tableName]
	if !found {
		return result, nil
	}

	for _, v := range tbl {
		result = append(result, v)
	}
	return result, nil
}

func (i *TestIntrinsics) Remove(e entity.Interface) error {
	tableName := entity.GetTableName(e)
	tbl, found := i.store[tableName]
	if !found {
		return nil
	}

	id := e.GetID()
	delete(tbl, id)
	return nil
}

func (i *TestIntrinsics) Block() subgraph.BlockRef {
	return &blockRef{
		id:        "0x1",
		num:       1,
		timestamp: time.Time{},
	}
}

func (i *TestIntrinsics) StepBelow(step int) bool {
	return i.step < step
}

func (i *TestIntrinsics) StepAbove(step int) bool {
	return i.step > step
}

func (i *TestIntrinsics) GetTokenInfo(address eth.Address) *eth.Token {
	tok := i.tokens[address.Pretty()]
	return tok
}

type TestCase struct {
	StoreData []*TypedEntity `yaml:"storeData" json:"storeData"`
	Tokens    []*TokenInfo   `yaml:"tokens" json:"tokens"`
	Events    []*TypedEvent  `yaml:"events" json:"events"`
}

type TokenInfo struct {
	Address     int    `yaml:"address" json:"address"`
	Name        string `yaml:"name" json:"name"`
	Symbol      string `yaml:"symbol" json:"symbol"`
	Decimals    int    `yaml:"decimals" json:"decimals"`
	TotalSupply int    `yaml:"total_supply" json:"total_supply"`
}

type TypedEntity struct {
	Type   string
	Entity entity.Interface
}

func (t *TypedEntity) UnmarshalJSON(data []byte) error {
	s := &struct {
		Type   string          `json:"type" yaml:"type"`
		Entity json.RawMessage `json:"entity" yaml:"entity"`
	}{}

	err := json.Unmarshal(data, &s)
	if err != nil {
		return err
	}

	var ent entity.Interface
	switch s.Type {
	case "user":
		tempEnt := &User{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "bundle":
		tempEnt := &Bundle{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "factory":
		tempEnt := &Factory{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "hour_data":
		tempEnt := &HourData{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "day_data":
		tempEnt := &DayData{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "token":
		tempEnt := &Token{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "token_hour_data":
		tempEnt := &TokenHourData{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "token_day_data":
		tempEnt := &TokenDayData{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "pair":
		tempEnt := &Pair{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "pair_hour_data":
		tempEnt := &PairHourData{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "pair_day_data":
		tempEnt := &PairDayData{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "liquidity_position":
		tempEnt := &LiquidityPosition{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "liquidity_position_snapshot":
		tempEnt := &LiquidityPositionSnapshot{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "transaction":
		tempEnt := &Transaction{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "mint":
		tempEnt := &Mint{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "burn":
		tempEnt := &Burn{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	case "swap":
		tempEnt := &Swap{}
		err := json.Unmarshal(s.Entity, &tempEnt)
		if err != nil {
			return err
		}
		ent = tempEnt
	}

	t.Entity = ent
	t.Type = s.Type

	return nil
}

type TypedEvent struct {
	Type  string
	Event interface{}
}

func (t *TypedEvent) UnmarshalJSON(data []byte) error {
	s := &struct {
		Type  string
		Event json.RawMessage
	}{}

	err := json.Unmarshal(data, &s)
	if err != nil {
		return err
	}

	var event interface{}
	switch s.Type {
	case "FactoryPairCreatedEvent":
		ev := &FactoryPairCreatedEvent{}
		err := json.Unmarshal(s.Event, &ev)
		if err != nil {
			return err
		}
		event = ev
	case "PairApprovalEvent":
		ev := &PairApprovalEvent{}
		err := json.Unmarshal(s.Event, &ev)
		if err != nil {
			return err
		}
		event = ev
	case "PairBurnEvent":
		ev := &PairBurnEvent{}
		err := json.Unmarshal(s.Event, &ev)
		if err != nil {
			return err
		}
		event = ev
	case "PairMintEvent":
		ev := &PairMintEvent{}
		err := json.Unmarshal(s.Event, &ev)
		if err != nil {
			return err
		}
		event = ev
	case "PairSwapEvent":
		ev := &PairSwapEvent{}
		err := json.Unmarshal(s.Event, &ev)
		if err != nil {
			return err
		}
		event = ev
	case "PairSyncEvent":
		ev := &PairSyncEvent{}
		err := json.Unmarshal(s.Event, &ev)
		if err != nil {
			return err
		}
		event = ev
	case "PairTransferEvent":
		ev := &PairTransferEvent{}
		err := json.Unmarshal(s.Event, &ev)
		if err != nil {
			return err
		}
		event = ev
	}

	t.Event = event
	t.Type = s.Type

	return nil
}
